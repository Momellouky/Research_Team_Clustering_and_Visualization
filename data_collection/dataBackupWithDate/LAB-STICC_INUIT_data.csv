title_s,abstract_s,keyword_s,authFullName_s,publicationDateY_i
Virtual reality beyond design reviews in shipbuilding : the need for industry-tailored immersive data interaction,"In the context of shipbuilding\, the potential of virtual reality (VR) as a visualization tool has been demonstrated [1\, 2]. However\, many conditions must be met for VR to be widely adopted in the shipbuilding industry. It primarily must be seamlessly integrated into current workflows. The shipbuilding industry will likely first need to tame its data with efficient models accessible throughout the ship's lifecycle. However\, some productivity issues with VR have not yet been identified clearly. While working to develop a VR design tool for ship outfitting\, it became clear to us that there is a need for industrydriven development of efficient data interaction and manipulation tools in VR. As an example of such new manipulation tools\, we are currently developing a new way to input text in VR that is efficient and easy-to-learn through handwriting. The evaluation of this system highlights the need for more controlled and systematic testing of VR tools in the shipbuilding industry to justify investments and adoption.","Shipbuilding,Industry,Virtual reality","Nicolas Fourrier,Mustapha Benaouicha,Guillaume Moreau,Jean-Marie Normand",2022
Human-centered Evaluation of 3D Radial Layouts for Centrality Visualization,"In this paper we propose improvements to the 3D radial layouts that make it possible to visualize centrality measures of the nodes in a graph. Our improvements mainly relate edge drawing and the evaluation of the 3D radial layouts. First\, we projected not only the nodes but also the edges onto the visualization surfaces in order to reduce the node overlap that could be observed in previous 3D radial layouts. Secondly\, we proposed a human-centered evaluation in order to compare the efficiency score and the time to complete tasks of the 3D radial layouts to those of the 2D radial layouts. The evaluation tasks proposed are related to the central nodes\, the peripheral nodes and the dense areas of a graph. The results showed that 3D layouts can perform significantly better than 2D layouts in terms of efficiency when tasks are related to the central and peripheral nodes\, while the difference in time is not statistically significant between these various layouts. Additionally\, we found that the participants preferred interacting with 3D layouts over 2D layouts.","3D Graph Visualization,Centrality Visualization,Graph Layout Evaluation","Piriziwè Kobina,Thierry Duval,Laurent Brisson,Anthony David",2022
Interpretable Machine Learning for Meteorological Data,,,"Ngoan Thanh Trieu,Bernard Pottier,Vincent Rodin,Hiep Xuan Huynh",2021
"Nouvelles visualisations 3D collaboratives de graphes pour l'exploration de relations intra et inter communautés,New 3D collaborative graph visualizations for intra and inter communities'relationships exploration","L’objectif de cette thèse était d’étudier les contributions de la visualisation 3Dimmersive par rapport à la visualisation classique 2D afin d’améliorer l’exploration et l’analyse des relations intracommunautés et intercommunautés représentées sous forme de graphes. Après une analyse de l’état de l’art sur la théorie des graphes et ses applications à l’analyse des réseaux sociaux et sur des méthodes de visualisation de graphes\, nous avons proposé deux approches de visualisation de graphes : une visualisation exocentrique\, qui permet à un utilisateur de manipuler un graphe comme un objet\, pour permettre de visualiser intuitivement la centralité des nœuds et une visualisation égocentrique\, spécialement adaptée à l’exploration d’un graphe en environnement immersif\, où notre mécanisme de rétractation de l’espace d’affichage du graphe permet à un utilisateur d’avoir une vision d’ensemble du graphe tout en restant en mode égocentrique. Les applications de ces travaux sont tout aussi civiles que militaires.,The aim of this thesis was to study the contributions of immersive 3D visualization compared to classical 2D visualization in order to improve the exploration and analysis of intra-community and inter-community relationships represented as graphs. After an analysis of the state of the art on graph theory and its applications to social network analysis and on graph visualization methods\, we proposed two graph visualization approaches: an exocentric visualization\, which allows a user to manipulate a graph as an object\, to intuitively visualize the centrality of the nodes and an egocentric visualization\, especially adapted to the exploration of a graph in an immersive environment\, where our mechanism of retraction of the graph display space allows a user to have an overall view of the graph while remaining in egocentric mode. The applications of this work are both civilian and military.","3D visualization,Virtual reality,Community graphs,Graph analysis,Visualisation 3D,Réalité virtuelle,Graphes de communautés,Analyse de graphes",Piriziwè Kobina,2022
A Two-Level Highlighting technique based on gaze direction to improve targets pointing and selection on a touch screen,"In this paper\, we present an approach to improve pointing methods and target selection on tactile human-machine interfaces. The proposed approach defines a two-level highlighting technique (TLH) based on the direction of gaze for target selection on HMIs on a touch screen. The technique is based on the orientation of the user's head to approximate the direction of his gaze and uses this data to preselect the potential targets to be selected by the user. An experimental system with a multimodal interface has been prototyped to assess the impact of TLH on target selection on a touch screen\, to compare its performance with that of traditional methods (mouse and touch). We conducted an experiment to assess the effectiveness of our proposition in objective terms of the rate of selection errors made\, the time for completion of the task. We also made a subjective estimate of ease of use\, suitability for selection\, confidence brought by the TLH\, and contribution of TLH to improving the selection of targets. Statistical results have shown that the proposed TLH significantly reduces the selection error rate and the time to complete tasks. For the completion time\, the TLH added to the touch (TLHT) using the direction of the gaze gave performances equal to those obtained using the TLH added to the mouse cursor (TLHM). Finally\, participants found that TLH has significantly improved target selection methods and expressed the wish to be able to use it in the future.",,"Valéry M. Monthé,Thierry Duval",2020
Improving Reward Estimation in Goal-Conditioned Imitation Learning with Counterfactual Data and Structural Causal Models,"Imitation learning has emerged as a pragmatic alternative to reinforcement learning for teaching agents to execute specific tasks\, mitigating the complexity associated with reward engineering. However\, the deployment of imitation learning in real-world scenarios is hampered by numerous challenges. Often\, the scarcity and expense of demonstration data hinder the effectiveness of imitation learning algorithms. In this paper\, we present a novel approach to enhance the sample efficiency of goal-conditioned imitation learning. Leveraging the principles of causality\, we harness structural causal models as a formalism to generate counterfactual data. These counterfactual instances are used as additional training data\, effectively improving the learning process. By incorporating causal insights\, our method demonstrates its ability to improve imitation learning efficiency by capitalizing on generated counterfactual data. Through experiments on simulated robotic manipulation tasks\, such as pushing\, moving\, and sliding objects\, we showcase how our approach allows for the learning of better reward functions resulting in improved performance with a limited number of demonstrations\, paving the way for a more practical and effective implementation of imitation learning in real-world scenarios.","Imitation Learning,Causality,Structural Causal Models,Counterfactual Reasoning","Mohamed Khalil Jabri,Panagiotis Papadakis,Ehsan Abbasnejad,Gilles Coppin,Javen Shi",2023
SABLIER : a Tangible Interactor to Navigate through Space and Time,"Historians use spatio-temporal navigation for their models and studies of historical evolutions and events. Their findings can then be exhibited in cultural mediation centers or museums. The latter\, both to facilitate the transmission of knowledge and to make their exhibitions more attractive\, are now exploiting new technologies. Indeed\, digital systems allow\, among other things\, visitors to navigate spatially and temporally in virtual reconstructions of historical environments. We propose to combine these virtual representations with a tangible interface to provide visitors with an immersive experience and engaging interactions. To do so\, we have set up a co-design process involving cultural mediation actors (museum directors\, historians\, etc.). The result is SABLIER\, a tangible interactor to navigate through space and time based on the interaction metaphors and natural affordance of an hourglass. Finally\, we have conducted an evaluation of the acceptability of our interactor\, whose results are positive.","Tangible User Interface,Cultural Mediation,Virtual Reality","Pierre Mahieux,Romain Biannic,Sébastien Kubicki,Ronan Querrec",2022
A Systematic Review of Navigation Assistance Systems for People with Dementia,"Technological developments provide solutions to alleviate the tremendous impact on the health and autonomy due to the impact of dementia on navigation abilities. We systematically reviewed the literature on devices tested to provide assistance to people with dementia during indoor\, outdoor and virtual navigation (PROSPERO ID number: 215585). Medline and Scopus databases were searched from inception. Our aim was to summarize the results from the literature to guide future developments. Twenty-three articles were included in our study. Three types of information were extracted from these studies. First\, the types of navigation advice the devices provided were assessed through: (i) the sensorial modality of presentation\, e.g.\, visual and tactile stimuli\, (ii) the navigation content\, e.g.\, landmarks\, and (iii) the timing of presentation\, e.g.\, systematically at intersections. Second\, we analyzed the technology that the devices were based on\, e.g.\, smartphone. Third\, the experimental methodology used to assess the devices and the navigation outcome was evaluated. We report and discuss the results from the literature based on these three main characteristics. Finally\, based on these considerations\, recommendations are drawn\, challenges are identified and potential solutions are suggested. Augmented reality-based devices\, intelligent tutoring systems and social support should particularly further be explored.","Information Interfaces and Representation HCI,Health care,Navigation,Dementia,Alzheimer,Augmented reality","Léa Pillette,Guillaume Moreau,Jean-Marie Normand,Manon Perrier,Anatole Lécuyer,Melanie Cogne",2022
An Hybrid Model for Rectal Tumour Response Prediction during Radiotherapy,,,"Sena Apeke,Laurent Gaubert,Nicolas Boussion,Dimitris Visvikis,Olivier Saut,Thierry Colin,Philippe Lambin,Vincent Rodin,Pascal Redou",2022
"Conserver et restituer le patrimoine industriel grâce à la réalité virtuelle et augmentée,Preserving and Reviving Industrial Heritage with Virtual and Augmented Realities",,,"Anne Wartelle,Marie-Morgane Abiven,Florent Laroche,Ronan Querrec",2023
Speech Perception and Implementation in a Virtual Medical Assistant,"In emergency medical procedures\, positive and trusting interactions between followers and leaders are imperative. That interaction is even more important when a virtual agent assumes the leader role and a human assumes the follower role. In order to manage the human-computer interaction\, situational leadership is employed to match the human follower to an appropriate leadership style embodied by the agent. Situational leadership was used to create 33 utterances indicative of the four different leadership styles. A participant evaluation was then carried out in order to examine (1) whether perceptions of leader trust and motivation vary dependent on both readiness level and utterance syntax and (2) whether follower ability and willingness are affected by the leader’s speech. We found that general perceptions of leadership behavior influenced follower performance and that the leader’s speech influences followers’ ability. Finally\, we demonstrate how the results of this study are implemented in a virtual agent system.","Situational leadership,Medicine,Speech,Virtual agent,Embodied conversational agent","Aryana Collins Jackson,Yann Glémarec,Elisabetta Bevacqua,Pierre de Loor,Ronan Querrec",2022
How to Grasp the Complexity of Self-Organised Robot Swarms?,"Robot swarms consist of large numbers of autonomous robots\, whose behaviour has been greatly inspired by existing complex biological\, physical or chemical systems. This is especially the case for behaviours that involve mechanisms leading to spatial self-organisation of robots. The complex nature of these behaviours prevents a human operator from keeping a mental model of them\, which makes it difficult to interact with them\, even though this is necessary in certain cases: prediction of a loss of stability\, detection of blocking situations\, etc. How to allow an operator to grasp the complexity of self-organised robot swarms? This article aims at providing leads to answer this question\, by investigating what humans are capable of perceiving of a complex system\, and what additional information could be needed to enable them to understand its dynamics and state\, and to predict the effects of their control. We first present what an operator is able to perceive from a large number of agents\, self-organised or not\, through a state of the art of existing works in cognitive sciences\, vision and swarm robotics. Secondly\, we identify in the literature the different types of information on robot swarms that are transmitted to the operator\, with the aim of facilitating his perception and improving his understanding. Finally\, we discuss what could be the information needed to build a mental model of the operator\, the avenues being explored and the possible challenges to be taken into account.","Robot Swarm,Self-Organisation,Perception,Interaction","Jérémy Rivière,Aymeric Hénard,Etienne Peillard,Sébastien Kubicki,Gilles Coppin",2023
Detection of Removed Objects in 3D Meshes Using Up-to-Date Images for Mixed-Reality Applications,"Precise knowledge of the real environment is a prerequisite for the integration of the real and virtual worlds in mixed-reality applications. However\, real-time updating of a real environment model is a costly and difficult process; therefore\, hybrid approaches have been developed: An updated world model can be inferred from an offline acquisition of the 3D world\, which is then updated online using live image sequences under the condition of developing fast and robust change detection algorithms. Current algorithms are biased toward object insertion and often fail in object removal detection; in an environment where there is uniformity in the background—in color and intensity—the disappearances of foreground objects between the 3D scan of a scene and the capture of several new pictures of said scene are difficult to detect. The novelty of our approach is that we circumvent this issue by focusing on areas of least change in parts of the scene that should be occluded by the foreground. Through experimentation on realistic datasets\, we show that this approach results in better detection and localization of removed objects. This technique can be paired with an insertion detection algorithm to provide a complete change detection framework","Change detection,Mixed reality,3D model,Image sequence,Projection,Occluding object,Foreground object","Olivier Roupin,Matthieu Fradet,Caroline Baillard,Guillaume Moreau",2021
"Tangible Interactions to Navigate Through Space and Time Inside a Virtual Environment,Interactions Tangibles pour Naviguer Spatialement et Temporellement au sein d'un Environnement Virtuel",,"Tangible User Interface,Virtual Reality,Cultural Heritage","Pierre Mahieux,Sébastien Kubicki,Sylvain Laubé,Ronan Querrec",2021
"Augmented Reality Authoring of Digital Twins: Design\, Implementation and Evaluation in an Industry 4.0 Context","This paper deals with Digital Twins (DTs) for Industry 4.0 factories\, and their implementation in the context of a reconfigurable factory. This context implies a modification of the layout of the workstations during production\, and thus requires a live update of the digital twins according to these modifications. We needed this update done by the operators directly on the workstations using an AR authoring tool. A literature review helped us to determine the criteria that a tool should fulfill in order to achieve this goal. The most important criteria are that the tool should be suitable for use by operators not trained in AR\, that the learning curve should be short\, and that it should be usable in a reconfigurable factory context. We created a DT containing all the necessary factory data and 3D models of the workstation interaction zones of a real assembly line. We then developed a tool enabling operators to match the DTs with their physical twin (PT) in AR\, as well as to update their position in case of a reconfiguration. The experimentation we carried out confirms our analysis and shows us that it is possible to deploy a DT in a factory quite simply if the positioning of the DTs is done by direct manipulation (the 3D objects are co-located with the operator's hand) with the help of an AR display device.","Digital Twin,Augmented Reality,Gestural Interaction,Industry 40,AR Authoring","Pierre Begout,Sébastien Kubicki,Emmanuel Bricard,Thierry Duval",2022
"Mirror\, Mirror on My Phone: Investigating Dimensions of Self-Face Perception Induced by Augmented Reality Filters","The main use of Augmented Reality (AR) today for the general public is in applications for smartphones. In particular\, social network applications allow the use of many AR filters\, modifying users' environments but also their own image. These AR filters are increasingly and frequently being used and can distort in many ways users' facial traits. Yet\, we still do not know clearly how users perceive their faces augmented by these filters. In this paper\, we present a study that aims to evaluate the impact of different filters\, modifying several facial features such as the size or position of the eyes\, the shape of the face or the orientation of the eyebrows\, or adding virtual content such as virtual glasses. These filters are evaluated via a self-evaluation questionnaire\, asking the participants about the personality\, emotion\, appeal and intelligence traits that their distorted face conveys. Our results show relative effects between the different filters in line with previous results regarding the perception of others. However\, they also reveal specific effects on self-perception\, showing\, inter alia\, that facial deformation decreases participants' credence towards their image. The findings of this study covering multiple factors allow us to highlight the impact of face deformation on user perception but also the specificity related to this use in AR\, paving the way for new works focusing on the psychological impact of such filters.","Augmented Reality,Self-perception,Face perception","Rebecca Fribourg,Etienne Peillard,Rachel Mcdonnell",2021
Simulations of a Computational Model for a Virtual Medical Assistant,"We propose a virtual medical assistant to guide both novice and expert caregivers through a procedure without the direct help of medical professionals. Our medical assistant uses situational leadership to handle all interaction with a caregiver\, which works by identifying the readiness level of the caregiver in order to match them with an appropriate style of communication. The agent system (1) obtains caregiver behavior during the procedure\, (2) calculates a readiness level of the caregiver using that behavior\, and (3) generates appropriate agent behavior to progress the procedure and maintain a positive interaction with the caregiver.","Intelligent Agents,Embodied Conversational Agents,Human-computer Interaction,Situational Leadership,Medicine,Simulation","Aryana Collins Jackson,Marlène Gilles,Eimar Wall,Elisabetta Bevacqua,Pierre de Loor,Ronan Querrec",2022
Handwriting for Efficient Text Entry in Industrial VR Applications: Influence of Board Orientation and Sensory Feedback on Performance,"Text entry in Virtual Reality (VR) is becoming an increasingly important task as the availability of hardware increases and the range of VR applications widens. This is especially true for VR industrial applications where users need to input data frequently. Large-scale industrial adoption of VR is still hampered by the productivity gap between entering data via a physical keyboard and VR data entry methods. Data entry needs to be efficient\, easy-to-use and to learn and not frustrating. In this paper\, we present a new data entry method based on handwriting recognition (HWR). Users can input text by simply writing on a virtual surface. We conduct a user study to determine the best writing conditions when it comes to surface orientation and sensory feedback. This feedback consists of visual\, haptic\, and auditory cues. We find that using a slanted board with sensory feedback is best to maximize writing speeds and minimize physical demand. We also evaluate the performance of our method in terms of text entry speed\, error rate\, usability and workload. The results show that handwriting in VR has high entry speed\, usability with little training compared to other controller-based virtual text entry techniques. The system could be further improved by reducing high error rates through the use of more efficient handwriting recognition tools. In fact\, the total error rate is 9.28% in the best condition. After 40 phrases of training\, participants reach an average of 14.5 WPM\, while a group with high VR familiarity reach 16.16 WPM after the same training. The highest observed textual data entry speed is 21.11 WPM.","Virtual reality,Réalité virtuelle","Nicolas Fourrier,Guillaume Moreau,Mustapha Benaouicha,Jean-Marie Normand",2023
Supervised classification of operator functional state based on physiological data: application to drones swarm piloting,,,"Alexandre Kostenko,Philippe Rauffet,Gilles Coppin",2021
The sense of embodiment in Virtual Reality and its assessment methods,"The sense of embodiment refers to the sensations of being inside\, having\, and controlling a body. In virtual reality\, it is possible to substitute a person's body with a virtual body\, referred to as an avatar. Modulations of the sense of embodiment through modifications of this avatar have perceptual and behavioural consequences on users that can influence the way users interact with the virtual environment. Therefore\, it is essential to define metrics that enable a reliable assessment of the sense of embodiment in virtual reality to better understand its dimensions\, the way they interact\, and their influence on the quality of interaction in the virtual environment. In this review\, we first introduce the current knowledge on the sense of embodiment\, its dimensions (senses of agency\, body ownership\, and self-location)\, and how they relate the ones with the others. Then\, we dive into the different methods currently used to assess the sense of embodiment\, ranging from questionnaires to neurophysiological measures. We provide a critical analysis of the existing metrics\, discussing their advantages and drawbacks in the context of virtual reality. Notably\, we argue that real-time measures of embodiment\, which are also specific and do not require double tasking\, are the most relevant in the context of virtual reality. Electroencephalography seems a good candidate for the future if its drawbacks (such as its sensitivity to movement and practicality) are improved. While the perfect metric has yet to be identified if it exists\, this work provides clues on which metric to choose depending on the context\, which should hopefully contribute to better assessing and understanding the sense of embodiment in virtual reality.","Virtual reality,Review,Embodiment,Evaluation,Assessment method","Martin Guy,Jean-Marie Normand,Camille Jeunet-Kelway,Guillaume Moreau",2023
Embedded Computation Architectures for Autonomy in Unmanned Aircraft Systems (UAS),"This paper addresses the challenge of embedded computing resources required by future autonomous Unmanned Aircraft Systems (UAS). Based on an analysis of the required onboard functions that will lead to higher levels of autonomy\, we look at most common UAS tasks to first propose a classification of UAS tasks considering categories such as flight\, navigation\, safety\, mission and executing entities such as human\, offline machine\, embedded system. We then analyse how a given combination of tasks can lead to higher levels of autonomy by defining an autonomy level. We link UAS applications\, the tasks required by those applications\, the autonomy level and the implications on computing resources to achieve that autonomy level. We provide insights on how to define a given autonomy level for a given application based on a number of tasks. Our study relies on the state-of-the-art hardware and software implementations of the most common tasks currently used by UAS\, also expected tasks according to the nature of their future missions. We conclude that current computing architectures are unlikely to meet the autonomy requirements of future UAS. Our proposed approach is based on dynamically reconfigurable hardware that offers benefits in computational performance and energy usage. We believe that UAS designers must now consider the embedded system as a masterpiece of the system.",,"Luis Mejias,Jean-Philippe Diguet,Catherine Dezan,Duncan Campbell,Jonathan Kok,Gilles Coppin",2021
Human Model For Industrial System And Product Design In Industry 5.0: A Case Study,"Human performance models can be included in industrial system models to improve the design of the industrial system\, manufacturing processes\, and product design. In our use case\, a critical process in the production of a new airplane was being considered for automation. This process requires the highest quality assurance and is normally performed manually. Robot assistance could improve quality and efficiency. A human performance model focused on worker fatigue was developed\, taking into account characteristics of the workers\, robots\, and tasks. Two different automation scenarios (fully manual\, semi-automated)\, with different worker characteristics such as skill\, age\, motivation\, etc. were studied. Using historical production line data in the fully manual scenario\, and simulated data for the semi-automated scenario\, global fatigue scores and graphical visualization were generated by the model for each scenario\, allowing the system architects to understand the effects of the future production system on workers\, including errors\, time lost\, costs and overall resilience of the system.","Industry 50,Production and manufacturing,Simulation model,Worker fatigue","Arnaud Allemang--Trivalle,Jérémie Donjat,Gaëlic Bechu,Gilles Coppin,Oliver W. Klaproth,Andreas Mitschke,Arnd Schirrmann,Mathieu Chollet,Caroline Gl Cao",2023
Towards a Sensitive Urban Wind Representation in Virtual Reality,"Wind can influence people’s behavior and their way of inhabiting an architectural or urban space. Furthermore\, virtual reality (VR) enables the simulation of different physical and sensitive phenomena such as the wind. We aim to analyze the effects of different wind representations in terms of perception of its properties and sense of presence in VR. We carry out two within-subject studies aiming at evaluating different wind representation suggestions (including audiovisual and tactile stimuli) to identify their effects on wind properties’ perception and sense of presence in the VR scene. Our analysis showed significant effects of tactile restitution over the visual effects used in the study\, both for understanding wind properties and for increasing the sense of presence in the VR scene. The tactile condition (T) reduced the estimation error of wind direction by 27% compared to the visual condition (V). The wind force error was reduced by 9.8% using (T) with (V). (T) increased the sense of presence by 12.2% compared to (V). Our second experiment showed an overestimation of the wind force perceived compared to the reference value of the Beaufort scale. For the maximum force value evaluated\, the average result was 91% higher than the reference value\, while for the lower\, the average answer was 77% higher than the reference value. Previous studies have evaluated wind rendering in virtual reality\, and others have studied the visualization of wind simulation results. To our knowledge\, our study is the first to compare the perception of these two types of representations as well as the effects of wind on elements of the context. We also compared the wind perception to a reference-based method\, the Beaufort scale.","Wind perception,Wind representation,Virtual reality,User experiment,Sense of presence,Vizualisation,Urban 3D model,Modeling & Simulation","Gabriel Giraldo,Myriam Servières,Guillaume Moreau",2022
"Towards geometric and semantic change detection for mixed reality experiences,Vers une détection des changements géométriques et sémantiques pour des expériences de réalité mixte","Photorealistic Augmented Reality (AR) –or “Mixed Reality”– is applicable to various immersive experiences\, from entertainment to simulation-based training\, and for previsualization tasks. The realistic integration of virtual elements requires an accurate and up-to-date model of the real scene's geometry and semantic contents. The 3D structure of the environment impacts the visual rendering as well as the spatial layout of the virtual content and its interactions with real objects. Given the hardware constraints of widely available AR devices\, it is impractical to thoroughly scan the geometry of the scene with each use. Still\, some the scene's structural information will remain constant over time only requiring local updates to accurately represent the scene's current state. The aim of this doctoral study has been to provide the means to identify and correct areas of change in a scene through detection of inconsistencies between a prior representation and an current observations. In this thesis\, we present the completion of a lightweight reprojection-based geometric change detection framework. We also present the elaboration of a graph-based semantic scene model for Mixed Reality\, and a method for its generation from semantic analysis. This model will then be used in a 3D scene registration system\, in order to test its applicability to the localization task in AR.,La Réalité Augmentée (RA) photoréaliste (« Réalité Mixte ») est utile pour diverses applications immersives\, du divertissement visuel à la formation par simulation\, et pour la prévisualisation d'aspect. L'intégration réaliste d’éléments virtuels dans une scène nécessite un modèle à jour de sa géométrie et son contenu sémantique. La structure 3D d’un environnement impacte le rendu visuel ainsi que l'organisation spatiale du contenu virtuel et ses interactions avec le réel. En raison des limitations matérielles des appareils RA grand public\, faire un scan géométrique exhaustif de la scène à chaque utilisation est irréaliste. Néanmoins\, une partie de l'information structurelle dans la scène reste inchangée et ne requiert que des mises à jour locales pour rester fidèle au réel. Cette thèse a pour objectif de donner les moyens d'identifier et corriger les régions changeantes d'une scène en détectant les différences entre une représentation antérieure et des observations courantes. Nous présenterons un nouveau système de détection de changements géométrique léger\, utilisant une méthode de reprojection d'images. Nous présenterons également l'élaboration d'un modèle sémantique de scène pour la Réalité Mixte à base de graphes\, ainsi qu'une méthode de génération de ce modèle par analyse sémantique. Ce même modèle sera alors exploité dans un système d'alignement de scènes 3D\, pour évaluer son applicabilité à la localisation en RA.","Mixed reality,Change detection,Semantic analysis,3D reconstruction,Réalité mixte,Détection de changements,Analyse sémantique,Reconstruction 3D",Olivier Roupin,2023
"Outil d'authoring 3D du jumeau numérique de lignes d'assemblage pour augmenter l'opérateur de l'usine du futur,3D authoring tool of the digital twin of assembly lines to augment the operator of the factory of the future","Cette thèse traite des jumeaux numériques pour les usines de l'industrie 4.0 et de leur mise en œuvre dans le cadre d'une usine reconfigurable\, dans un contexte d'assistance aux opérateurs des lignes de production à l'aide de techniques de Réalité Augmentée (RA). Il faut pouvoir modifier l'agencement du poste de travail pendant la production\, et nécessite donc une mise à jour en direct des jumeaux numériques en fonction de ces modifications\, faite par les opérateurs directement sur les postes de travail\, à l'aide d'un outil basé RA. Une revue de la littérature a aidé à déterminer les critères qu'un outil doit remplir pour atteindre cet objectif : l'outil doit être adapté à une utilisation par des opérateurs non formés à la RA\, la courbe d'apprentissage doit être courte\, et il doit être utilisable dans un contexte d'usine reconfigurable. Un modèle de Jumeau Numérique a été proposé afin de contenir toutes les données d'usine nécessaires et les modèles 3D des zones d'interaction d'un vrai poste de travail d'assemblage. Un outil a ensuite été développé pour permettre aux opérateurs de faire correspondre les modèles 3D des jumeaux numériques avec leur jumeau physique en RA\, ainsi que pour mettre à jour leur position en cas de reconfiguration. L'expérimentation effectuée confirme que le raisonnement est bon si le positionnement des modèles 3D de ces Jumeaux Numériques se fait par manipulation directe (les objets 3D sont co-localisés avec la main de l'opérateur) à l'aide d'un dispositif d'affichage RA.,This thesis deals with digital twins for factories in Industry 4.0 and their implementation in the context of a reconfigurable factory\, in the context of assisting production line operators using techniques of Augmented Reality (AR). It is necessary to be able to modify the layout of the workstation during production\, and therefore requires a live update of the digital twins according to these modifications\, made by the operators directly on the workstations\, using a AR based tool. A review of the litterature helped determine the criteria a tool must meet to achieve this goal: the tool must be suitable for use by non-AR trained operators\, the learning curve must be short\, and it must be usable in a reconfigurable factory context. A Digital Twin model has been proposed to contain all the necessary factory data and 3D models of the interaction areas of a real assembly workstation. A tool was then developed to allow operators to match the 3D models of the digital twins with their physical twin in AR\, as well as update their position in the event of a reconfiguration. The experimentation carried out confirms that the reasoning is correct if the positioning of the 3D models of theses Digital Twins is done by direct manipulation (the 3D objects are co-located with the operator's hand) using an AR display device.","3D authoring tool for AR,AR authoring,Digital twin,Industry 40,Authoring 3D,Authoring RA,Jumeau numérique,Industrie 40",Pierre Bégout,2022
Direct and Indirect vSLAM Fusion for Augmented Reality,"Augmented reality (AR) is an emerging technology that is applied in many fields. One of the limitations that still prevents AR to be even more widely used relates to the accessibility of devices. Indeed\, the devices currently used are usually high end\, expensive glasses or mobile devices. vSLAM (visual simultaneous localization and mapping) algorithms circumvent this problem by requiring relatively cheap cameras for AR. vSLAM algorithms can be classified as direct or indirect methods based on the type of data used. Each class of algorithms works optimally on a type of scene (e.g.\, textured or untextured) but unfortunately with little overlap. In this work\, a method is proposed to fuse a direct and an indirect methods in order to have a higher robustness and to offer the possibility for AR to move seamlessly between different types of scenes. Our method is tested on three datasets against state-of-the-art direct (LSD-SLAM)\, semi-direct (LCSD) and indirect (ORBSLAM2) algorithms in two different scenarios: a trajectory planning and an AR scenario where a virtual object is displayed on top of the video feed; furthermore\, a similar method (LCSD SLAM) is also compared to our proposal. Results show that our fusion algorithm is generally as efficient as the best algorithm both in terms of trajectory (mean errors with respect to ground truth trajectory measurements) as well as in terms of quality of the augmentation (robustness and stability). In short\, we can propose a fusion algorithm that\, in our tests\, takes the best of both the direct and indirect methods.",,"Mohamed Outahar,Guillaume Moreau,Jean-Marie Normand",2021
The Spherical Retractable Bubble Space: an Egocentric Graph Visualization throughout a Retractable Visualization Space,"In this paper we present a new egocentric metaphor for graph visualization that consists in positioning a graph between two concentric spheres of different radii. It improves the expansion of the nodes in space\, contrary to the 3D spatialization algorithms. Edge drawing is optimized by pushing all the edges into the area delimited by our two concentric spheres\, so that a user can move freely without being encumbered by edges. Our new metaphor also makes it possible to reduce the display angles to have a global view of the graph without leaving the egocentricity.","Big Data Visualization,Virtual Reality,Graph Visualization","Piriziwè Kobina,Thierry Duval,Laurent Brisson",2023
Improving Neural Architecture Search by Mixing a FireFly algorithm with a Training Free Evaluation,"Neural Architecture Search (NAS) algorithms are used to automate the design of deep neural networks. Finding the best architecture for a given dataset can be time consuming since these algorithms have to explore a large number of networks\, and score them according to their performances to choose the most appropriate one. In this work\, we propose a novel metric that uses the Intra-Cluster Distance (ICD) score to evaluate the ability of an untrained model to distinguish between data in order to approximate its quality. We also use an improved version of the FireFly algorithm\, more robust to the local optimums problem than the baseline FireFly algorithm\, as a search technique to find the best neural network model adapted to a specific dataset. Experimental results on the different NAS Benchmarks show that our metric is valid for either scoring CNNs and RNNs\, and that our proposed FireFly algorithm can improve the result obtained by the state-of-art training-free methods",,"Nassim Mokhtari,Alexis Nédélec,Marlene Gilles,Pierre de Loor",2022
Virtual Workspace Positioning Techniques during Teleportation for Co-located Collaboration in Virtual Reality using HMDs,,,"Yiran Zhang,Thi Thuong Huyen Nguyen,Nicolas Ladevèze,Cédric Fleury,Patrick Bourdot",2022
How Can One Share a User’s Activity during VR Synchronous Augmentative Cooperation?,"Collaborative virtual environments allow people to work together while being distant. At the same time\, empathic computing aims to create a deeper shared understanding between people. In this paper\, we investigate how to improve the perception of distant collaborative activities in a virtual environment by sharing users’ activity. We first propose several visualization techniques for sharing the activity of multiple users. We selected one of these techniques for a pilot study and evaluated its benefits in a controlled experiment using a virtual reality adaptation of the NASA MATB-II (Multi-Attribute Task Battery). Results show (1) that instantaneous indicators of users’ activity are preferred to indicators that continuously display the progress of a task\, and (2) that participants are more confident in their ability to detect users needing help when using activity indicators.","Virtual reality,Collaborative virtual environments,Empathic computing,Collaborative awareness","Thomas Rinnert,James Walsh,Cédric Fleury,Gilles Coppin,Thierry Duval,Bruce Thomas",2023
How to Grasp the Complexity of Self-Organised Robot Swarms?,"Robot swarms consist of large numbers of autonomous robots\, whose behaviour has been greatly inspired by existing complex biological\, physical or chemical systems. This is especially the case for behaviours that involve mechanisms leading to spatial self-organisation of robots. The complex nature of these behaviours prevents a human operator from keeping a mental model of them\, which makes it difficult to interact with them\, even though this is necessary in certain cases: prediction of a loss of stability\, detection of blocking situations\, etc. How to allow an operator to grasp the complexity of self-organised robot swarms? This article aims at providing leads to answer this question\, by investigating what humans are capable of perceiving of a complex system\, and what additional information could be needed to enable them to understand its dynamics and state\, and to predict the effects of their control. We first present what an operator is able to perceive from a large number of agents\, self-organised or not\, through a state of the art of existing works in cognitive sciences\, vision and swarm robotics. Secondly\, we identify in the literature the different types of information on robot swarms that are transmitted to the operator\, with the aim of facilitating his perception and improving his understanding. Finally\, we discuss what could be the information needed to build a mental model of the operator\, the avenues being explored and the possible challenges to be taken into account.",,"Jérémy Rivière,Aymeric Hénard,Etienne Peillard,Sébastien Kubicki,Gilles Coppin",2023
Impact of Public Lighting Intensity on the Feeling of Safety in Virtual Reality,"Over the past decades the urban night landscapes have been associated with over-lighting\, which has become the norm. Arguably\, lighting systems play a major role in the city life (feeling of safety\, development of a night time economy and various night practices). But the urge for reducing energy consumption and protecting biodiversity must be considered while designing public lighting\, without compromising the feeling of safety. In this paper\, researchers from Urban Planning\, Psychology and Computer Science were gathered by the transdisciplinary research program ""Noz Breizh"". They are proposing an exploratory approach to use Virtual Reality to test different lighting intensities for studying its impact on the feeling of safety of pedestrians. As a first result we observed a logarithmic relation between the feeling of safety and the light intensity.","Urban Planning,Virtual Reality,Public Lighting,Well-being,Psychology,Safety","Olivier Augereau,Simon Bruno,Ignacio Pérez Allub,Edna Hernández González,Nathalie Le Bigot,Ronan Querrec",2023
"UCAV Swarm Performance Evaluation Stochastic Model,Modèle stochastique pour la détection d'essaims de véhicules aériens militaires","Cet article introduit un nouveau modèle de détection d'un essaim de véhicules aériens militaires autonomes par un radar sur des trajectoires prédéfinies. Ce modèle prend en compte l'impact des interactions entre membres de l'essaim sur la détection. Sur un scénario classique de pénétration\, on montre qu'un modèle simplifié permet de calculer facilement une borne supérieure sur les performances du modèle avec défaillances.","UCAV Swarm,Stochastic Model,Performance Evaluation","Stanislas de Charentenay,Alexandre Reiffers-Masson,Gilles Coppin",2023
Training and Data Analysis use cases for Cybersecurity through Mixed Reality Applications,"In this paper\, we will discuss our point of view of the use of Mixed Environments for Cybersecurity\, especially for training and data analysis purposes. We will argue that Collaborative Mixed Environments could merge training and analysis approaches by providing users with several points of view on cyber situations.",,"Alexandre Kabil,Thierry Duval,Marc-Oliver Pahl",2021
Virtual Reality Simulation for Multimodal and Ubiquitous System Deployment,"Multimodal IoT-based Systems (MIBS) are ubiquitous systems that use various connected devices as interfaces of interaction. However\, configuring and testing MIBS to ensure they correctly work in one's own environment is still challenging for most users: the trial and error process in situ is a tedious and time-consuming method. In this paper\, we aim to simplify the installation process of MIBS. Thus\, we propose a new VR methodology and a tool that allow the configuration and evaluation of MIBS thanks to realistic simulation. In our approach\, users can easily test various devices\, devices locations\, and interaction techniques without prior knowledge or dependence on the environment and devices availability. Contrary to on-the-field experiments\, there is no need to access the real environment and all the desired connected devices. Moreover\, our solution includes feedback features to better understand and assess devices interactive capabilities according to their locations. Users can also easily create\, collect and share their configurations and feedback to improve the MIBS\, and to help its installation in the real environment. To demonstrate the relevance of our VR-based methodology\, we compared it in a smart home with a tool following the same configuration process but on a desktop setup and with real devices. We show that users reached comparable configurations in VR and on-the-field experiments\, but the whole configuration and evaluation process was performed faster in VR.","Simulation,Prototyping/Implementation,Virtual Reality,Internet Of Things,Multimodal systems","Fabrice Poirier,Anthony Foulonneau,Jérémy Lacoche,Thierry Duval",2023
Cybercopters Swarm: Immersive Analytics for Alerts Classification based on Periodic Data,"This paper assesses the usefulness of an interactive and navigable 3D environment to help decision-making in cybersecurity. Malware programs frequently emit periodic signals in network logs. However\, normal periodical network activities\, such as software updates and data collection activities\, mask them. Thus\, if automatic systems use periodicity to successfully detect malware\, they will also detect ordinary activities as suspicious ones and will raise false positives. Hence\, there is a need to provide tools to sort the alerts raised by such software. Data visualizations can make it easier to categorize these alerts\, as proven by previous research. However\, traditional visualizations tools can struggle to display the large amount of data that needs to be treated in cybersecurity in a clear way. This is why this paper explores the use of Immersive Analytics to interact with complex datasets representations and to collect cues for alert classification. We created a prototype that uses a helical representation to underline periodicity in the distribution of one variable of a dataset. We tested this prototype in an alert triage scenario and compared it with a state of the art 2D visualization with regard to visualizations efficiency\, usability\, workload and flow induced.","Immersive Analytics,Cybersecurity,Periodic Signals,Virtual Reality,Alarm classification,HCI","Nicolas Delcombel,Thierry Duval,Marc-Oliver Pahl",2023
Virtual data sphere: inverse stereographic projection for immersive multi-perspective geovisualization,"Immersive geospatial visualization finds increasing application for navigation\, exploration\, and analysis. Many such require the display of data at different scales\, often in views with three-dimensional geometry. Multi-view solutions\, such as focus+context\, overview+detail\, and distorted projections can show different scales at the same time\, and help place an area of interest within its surroundings. By inverting the principle of stereographic projection – projecting spatial features from a map onto a virtual sphere which surrounds the viewer – we present a novel technique for immersive geospatial focus+context that aims to mitigate problems with existing solutions. This sphere can intersect the map\, dividing it into two parts: the inside of the sphere\, which stays unchanged\, and the outside\, which gets projected to the surface\, resulting in an inversion of the lens metaphor by distorting the context instead of the focus. This detail-in-context visualization maximizes the amount of context that can be legibly shown by the smooth compression inherent to the stereographic projection\, and by utilizing otherwise unused screen space in the sky. The projection method allows for easy control over the projection and distortion characteristics by varying only two main parameters – the sphere’s radius and its position. The omnidirectional nature of our system makes it particularly well-suited for immersive displays by accommodating typical immersive exploration and fully utilizing the additional visual space available. Applying our system to an urban environment\, we were able to solicit positive reactions during feedback sessions with experts from urbanism.","Geovisualization,Virtual Reality,Immersive Analytics,Multi-Perspective Views,Focus+Context","Maxim Spur,Vincent Tourre,Guillaume Moreau,Patrick Le Callet",2022
"Vers l'identification des phases d'apprentissage procédural en environnement virtuel,Towards the identification of procedural learning phases in a virtual environment","Les environnements virtuels utilisés pour acquérir des compétences génèrent de grandes quantités de données comportementales et apportent ainsi de nouvelles opportunités de compréhension de l'activité des apprenants. A par-tir de telles données\, une méthode de clustering a été utilisée dans la présente étude afin d'identifier des phases dans le processus d'apprentissage procédural. La reconnaissance de ces phases d'un point de vue comportemental permettrait de suivre en temps réel et de façon automatique la progression des individus et ainsi personnaliser les scénarios pédagogiques en environnement virtuel. Soixante-trois participants ont réalisé de façon répétée une procédure d'assemblage du cube de Soma en environnement virtuel. Les analyses montrent une amélioration des performances et une diminution du coût cognitif au fur et à mesure des répétitions de la tâche. Les résultats d'une approche multidimensionnelle de découpage de l'activité en différentes phases sont présentés et discutés.,Virtual environments used to acquire skills generate large amounts of behavioral data and thus provide new opportunities to understand learners' activity. From such data\, a clustering method was used in the present study to identify phases in the procedural learning process. The recognition of these phases from a behavioral point of view would allow to follow in real time and in an automatic way the progress of the individuals and thus to personalize the pedagogical scenarios in a virtual environment. Sixty-three participants repeatedly performed a Soma cube assembly procedure in a virtual environment. Analyses show an improvement in performance and a decrease in cognitive cost as the task is repeated. The results of a multidimensional approach of dividing the activity into different phases are presented and discussed.","Procedural learning,Mental workload,Behavioral data,Virtual environment,Learning phases,Apprentissage procédural,Charge de travail mental,Données comportementales,Environnement virtuel,Phases d'apprentissage","Anais Raison,Olivier Augereau,Nathalie Le Bigot,Frédéric Devillers,Sébastien Levieux,Franck Ganier",2023
Trust in Automation: Analysis and Model of Operator Trust in Decision Aid AI Over Time,"Understanding how human trust in AI evolves over time is essential to identify the limits of each party and provide solutions for optimal collaboration. With this goal in mind\, we examine the factors that directly or indirectly influence trust\, whether they come from humans\, AI\, or the environment. We then propose a summary of methods for measuring trust\, whether subjective or objective\, to show which ones are best suited for longitudinal studies. We then focus on the main driving force behind the evolution of trust: feedback. We justify how learning feedback can be transposed to trust and what types of feedback can be applied to impact the evolution of trust over time. After understanding the factors that influence and how to measure trust\, we propose an application example on a maritime surveillance tool with an AI-based decision aid.","Trust in Automation,Maritime Patrol,Longitudinal Experiment,Feedback,Human Factors,Cognitive Engineering","Vincent Fer,Daniel Lafond,Gilles Coppin,Mathias Bollaert,Olivier Grisvard,Pierre de Loor",2023
Interactive Multimodal System Characterization in the Internet of Things Context,"The internet of things (IoT) is a chance to provide users with pervasive environments in which they can interact naturally with the environment. Multimodal interaction is the domain that provides this naturalness by using different senses to interact. However\, the IoT context requires a specific process to create such multimodal systems. In this article\, we investigate the process of creating multimodal systems with connected devices as interaction mediums\, and provide an analysis of the existing tools to complete this process. We discuss tools that could be designed to support the creation process when the existing ones are not sufficient.","Multimodal Interaction,Tools,Internet of Things","Fabrice Poirier,Anthony Foulonneau,Jérémy Lacoche,Thierry Duval",2022
"Les interactions multimodales dans le contexte de l’internet des objets,Multimodal interactions in the context of the Internet of Things","Les MIBS sont des systèmes multimodaux utilisant des objets connectés comme interfaces d’interaction. Il faut des méthodes et des outils pour faciliter l’adaptation de ces systèmes aux spécificités des environnements d’exécution. D'un environnement à l'autre\, les objets connectés sont différents\, placés à des endroits différents\, avec des disponibilités variables. Un état de l’art a permis d’identifier les exigences à atteindre pour réaliser des MIBS\, puis de déterminer les fonctionnalités essentielles et les principales limitations des frameworks permettant de réaliser des MIBS. Cela nous a permis de proposer et développer notre propre framework. À ce stade une intervention humaine est nécessaire au processus d’adaptation des MIBS. Nous avons ensuite proposé une étude du cycle de vie de ces systèmes pour identifier les tâches\, rôles et outils intervenant dans ce processus d’adaptation. Pour outiller l’étape de déploiement des MIBS nous avons proposé une méthode et un outil proposant d’utiliser la Réalité Virtuelle (RV) pour configurer et évaluer des MIBS dans des modèles 3D d’environnements avant de passer au déploiement dans les environnements réels. Une expérimentation utilisateur a confirmé l’intérêt de cette approche.,MIBS are multimodal systems using connected objects as interaction interfaces. Methods and tools are needed to facilitate the adaptation of these systems to the specificities of the execution environments. From one environment to another\, the connected objects are different\, placed in different places\, with variable availability. A state of the art made it possible to identify the requirements to be met in order to create MIBS\, then to determine the essential functionalities and the main limitations of the frameworks allowing the creation of MIBS. This allowed us to propose and develop our own framework.At this stage\, human intervention is necessary for the MIBS adaptation process. We then proposed a study of the life cycle of these systems to identify the tasks\, roles and tools involved in this adaptation process. To equip the MIBS deployment stage\, we have proposed a method and a tool proposing to use Virtual Reality (VR) to configure and evaluate MIBS in 3D models of environments before moving on to deployment in real environments. A user experiment confirmed the interest of this approach.","Multimodal interactions,Ambiant systems,Connected objects,Internet of Things,Virtual reality,Interactions multimodales,Informatique ambiante,Objets connectés,Internet des objets,Réalité virtuelle",Fabrice Poirier,2023
Using Identification with AR Face Filters to Predict Explicit & Implicit Gender Bias,"Augmented Reality (AR) filters\, such as those used by social media platforms like Snapchat and Instagram\, are perhaps the most commonly used AR technology. As with fully immersive Virtual Reality (VR) systems\, individuals can use AR to embody different people. This experience in VR has been able to influence real world biases such as sexism. However\, there is little to no comparative research on AR embodiment's impact on societal biases. This study aims to set groundwork by examining possible connections between using gender changing Snapchat AR face filters and a person's predicted implicit and explicit gender biases. We discovered that participants who experienced identification with cross-gendered manipulations of themselves showed both greater and lesser amounts of bias against men and women. These results depended the filter user's gender\, the filter applied\, and the level of identification users reported with their AR manipulated selves. The results were similar to past VR findings but offered unique AR observations that could be useful for future bias intervention efforts.","Human-centered computing,Human computer interaction HCI,Interaction paradigms,Mixed / augmented reality,Human computer interaction HCI,HCI design and evaluation methods,User studies","Marie Jarrell,Etienne Peillard",2023
A classification of ethical issues in personnel scheduling,,"Ethics,Personnel scheduling,Classification","Vincent Bebien,Odile Bellenguez,Gilles Coppin,Anna Ma-Wyatt,Rachel Stephens",2023
Designing Speech with Computational Linguistics for a Virtual Medical Assistant Using Situational Leadership,"In emergency medical procedures\, positive and trusting interaction between followers and leaders are imperative. That interaction is even more important when a virtual agent assumes the leader role and a human assumes the follower role. In order to manage the human-computer interaction\, situational leadership is employed to match the human to an appropriate leadership style embodied by the agent. This paper explores how different leadership styles can be conveyed by a virtual agent through an analysis of utterances made by doctors and coordinators during emergency simulations. We create a corpus which comprises utterances from simulation videos of medical emergencies. Each utterance is annotated with a leadership style. After analysis involving k-means clustering\, we compile easily-reproducible rules that dictate how speech should appear in each leadership style for use in a virtual agent system.",,"Aryana Collins Jackson,Elisabetta Bevacqua,Pierre de Loor,Ronan Querrec",2021
Understanding Multi-View Collaboration between Augmented Reality and Remote Desktop Users,"Establishing an effective collaboration between augmented-reality (AR) and remote desktop users is a challenge because collaborators do not share a common physical space and equipment. Yet\, such asymmetrical collaboration configurations are common today for many design tasks\, due to the geographical distance of people or unusual circumstances such as a lockdown. We conducted a first study to investigate trade-offs of three remote representations of an AR workspace: a fully virtual representation\, a first-person view\, and an external view. Building on our findings\, we designed ARgus\, a multi-view video-mediated communication system that combines these representations through interactive tools for navigation\, previewing\, pointing\, and annotation. We report on a second user study that observed how 12 participants used ARgus to provide remote instructions for an AR furniture arrangement task. Participants extensively used its view transition tools\, while the system reduced their reliance on verbal instructions.","Augmented reality,Remote collaboration,Video-mediated communication","Arthur Fages,Cédric Fleury,Theophanis Tsandilas",2022
"Evaluation and Optimization of Underwater Image Restoration Algorithms,Évaluation et optimisation des algorithmes de restauration d'images sous-marines","On-board restoration of underwater images on embedded platforms such as marine drones is faced with many obstacles including image quality and real-time constraints. Confrontations met on the way vary from views to solution methods depending on the goals\, such as underwater vehicle realtime control and positioning or underwater object recognition. In this research\, five algorithms for underwater image restoration were studied and evaluated. In order to evaluate the quality of the performing algorithms nine evaluation criteria were used. Split into two types\, the no reference metrics assesses only the quality of the image results\, while the full reference criterion uses a reference image to estimate it. The calculation of these criteria allows each algorithm to be compared. Furthermore\, the possibility to optimise algorithms in order to make them applicable to meet real-time requirements on embedded platforms was investigated.,La restauration embarquée d'images sous-marines sur des plates-formes embarquées telles que les drones marins est confrontée à de nombreux obstacles dont la qualité des images et les contraintes de temps réel. Les confrontations rencontrées en cours de route varient des points de vue aux méthodes de solution en fonction des objectifs\, tels que le contrôle et le positionnement en temps réel du véhicule sous-marin ou la reconnaissance d'objets sous-marins. Dans cette recherche\, cinq algorithmes de restauration d'images sous-marines ont été étudiés et évalués. Afin d'évaluer la qualité des algorithmes performants\, neuf critères d'évaluation ont été utilisés. Divisés en deux types\, le critère sans référence évalue uniquement la qualité des résultats de l'image\, tandis que le critère avec référence complète utilise une image de référence pour l'estimer. Le calcul de ces critères permet de comparer chaque algorithme. En outre\, la possibilité d'optimiser les algorithmes afin de les rendre applicables pour répondre aux exigences du temps réel sur les plateformes embarquées a été étudiée.",,"Alan Le Boudec,Artur Mkrtchyan,Barbara Džaja,Vincent Rodin,Hai Nam Tran",2021
"Conception collaborative au travers de versions parallèles en Réalité Augmentée,Versioning Virtual Content for Collaborative Design in Augmented Reality","La Réalité Augmentée permet de faciliter la conception collaborative en superposant du contenu virtuel sur un objet physique. Cependant\, des conflits peuvent survenir dans le partage de l’espace 3D lorsque plusieurs concepteurs ajoutent ou modifient du contenu virtuel au même endroit pour développer des idées différentes. De plus\, même si la visibilité du contenu créé par un concepteur peut renforcer la créativité de ses collaborateurs\, elle peut également être source d’inhibition. Pour répondre à ces problèmes\, nous introduisons un framework conceptuel permettant à plusieurs versions des augmentations d’un même objet physique de coexister dans des espaces virtuels parallèles. Les utilisateurs peuvent ainsi partiellement ou totalement désynchroniser leur espace virtuel afin de générer leur propre contenu\, puis explorer les alternatives créées par leur collaborateur. Pour illustrer notre concept\, nous présentons un scénario de conception collaborative d’un vêtement sur un mannequin de couture physique grâce à du dessin 3D en Réalité Augmentée.,In Augmented Reality environments\, multiple designers can interact with virtual content that overlays their shared physical objects. However\, conflicts arise when two designers try to add or modify content around the same virtual space\, for example\, to explore a new path of ideas. Likewise\, although content created by one designer can serve as a source of inspiration for others\, it can also distract their creative process. To address those problems\, we introduce a conceptual framework that allows multiple versions of augmentations of the same physical object to coexist in parallel virtual spaces. According to our framework\, users can partially or totally desynchronize their virtual environment to generate their own content and then explore alternatives created by others. To illustrate it\, we present a scenario of collaborative design in Augmented Reality\, where two designers sketch in 3D around a physical sewing mannequin to design female dress.","Augmented Reality,Collaboration,Collaborative Design,Collaboration,Conception Collaborative,Réalité Augmentée","Arthur Fages,Cédric Fleury,Theophanis Tsandilas",2023
"Le patrimoine industriel en virtuel comme outil de formation,Virtual Industrial Heritage as a Training Tool","Il est généralement supposé que la formation en réalité virtuelle favorise l'implication et la mémorisation chez les apprenants. Nous souhaitons vérifier cette hypothèse dans un contexte d'éducation au patrimoine industriel. Le système développé\, générique\, établit un lien entre une ontologie décrivant un Paysage Industriel Culturel Sensoriel (PICS) donné\, et un Environnement Virtuel Intelligent Réaliste Sensoriel (EVIRS). Ce lien est rendu possible par la compatibilité entre l'ontologie SHS ANY-ARTEFACT et le métamodèle MASCARET. L'apprenant accède aux connaissances de l'ontologie en interagissant avec des Agents Conversationnels Autonomes (ACA)\, notamment en assistant à des scénarios joués par ces agents. Ce système nous permettra de mettre en œuvre des expérimentations pour évaluer les liens entre immersion et mémorisation.","Réalité virtuelle,Ontologies,Patrimoine industriel,Médiation,Apprentissage en immersion","Anne Wartelle,Ronan Querrec,Florent Laroche,Marie-Morgane Abiven,Sylvain Laubé,Marina Gasnier,Isabelle Astic",2023
"Manipulating the Sense of Embodiment in Virtual Reality: a study of the interactions between the senses of agency\, self-location and ownership","In Virtual Reality (VR)\, the Sense of Embodiment (SoE) corresponds to the feeling of controlling and owning a virtual body\, usually referred to as an avatar. The SoE is generally divided into three components: the Sense of Agency (SoA) which characterises the level of control of the user over the avatar\, the Sense of Self-Location (SoSL) which is the feeling to be located in the avatar and the Sense of Body-Ownership (SoBO) that represents the attribution of the virtual body to the user. While previous studies showed that the SoE can be manipulated by disturbing either the SoA\, the SoBO or the SoSL\, the relationships and interactions between these three components still remain unclear. In this paper\, we aim at extending the understanding of the SoE and the interactions between its components by 1) experimentally manipulating them in VR via a biased visual feedback\, and 2) understanding if each sub-component can be selectively altered or not. To do so\, we designed a within-subject experiment where 47 right-handed participants had to perform movements of their right-hand under different experimental conditions impacting the sub-components of embodiment: the SoA was modified by impacting the control of the avatar with visual biased feedback\, the SoBO was altered by modifying the realism of the virtual right hand (anthropomorphic cartoon hand or non-anthropomorphic stick ``fingers'') and the SoSL was controlled via the user's point of view (first or third person). After each trial\, participants rated their level of agency\, ownership and self-location on a 7-item Likert scale. Results' analysis revealed that the three components could not be selectively altered in this experiment. Nevertheless\, these preliminary results pave the way to further studies.",,"Martin Guy,Camille Jeunet-Kelway,Guillaume Moreau,Jean-Marie Normand",2022
LabInVirtuo — conserver et transmettre le patrimoine industriel en réalité virtuelle et augmentée,,"Réalité virtuelle,Patrimoine industrielle,Ingénierie des connaissances",Anne Wartelle,2023
CyberCopter: a 3D helical visualisation for periodic signals of cyber attacks,"This paper aims to assess the usefulness of 3D interactive interfaces to display periodic signals in a network. Past research has shown that data visualization simplifies alert classification drawn by periodicity-based Intrusion Detection Systems. However\, 2D visualizations have limitations such as screen space availability. This is why we created CyberCopter\, a prototype that uses a 3D helical representation to highlight periodic patterns in a dataset. We tested CyberCopter usability and efficiency in a fraud detection scenario. It scored 77 on the SUS questionnaire which demonstrates acceptable usability.","Virtual Reality,Cybersecurity,Immersive Analytics","Nicolas Delcombel,Alexandre Kabil,Thierry Duval,Marc-Oliver Pahl",2021
Time Navigation in a Virtual Environment using Tangible Interactions: application to the domain of History of Science and Technology,"The History of Science and Technology domain studies and describes the evolutions of human technical activities. Historians use new technologies such as Virtual Reality to reconstruct and expose the results of their research. In order to observe the evolutions of the studied systems inside a Virtual Environment\, the user must be able to navigate through time. We propose a model of time based on two scales and to use tangible interactions to navigate on these two timescales.","Models,Interaction paradigm,Tangible User Interface,Virtual Reality,History of Science and Technology,Cultural Heritage,Istory of Science and Technology","Pierre Mahieux,Sébastien Kubicki,Sylvain Laubé,Ronan Querrec",2021
Human Activity Recognition: A Spatio-temporal Image Encoding of 3D Skeleton Data for Online Action Detection,"Human activity recognition (HAR) based on skeleton data that can be extracted from videos (Kinect for example) \, or provided by a depth camera is a time series classification problem\, where handling both spatial and temporal dependencies is a crucial task\, in order to achieve a good recognition. In the online human activity recognition\, identifying the beginning and end of an action is an important element\, that might be difficult in a continuous data flow. In this work\, we present a 3D skeleton data encoding method to generate an image that preserves the spatial and temporal dependencies existing between the skeletal joints.To allow online action detection we combine this encoding system with a sliding window on the continous data stream. By this way\, no start or stop timestamp is needed and the recognition can be done at any moment. A deep learning CNN algorithm is used to achieve actions online detection.","Online Action Recognition,Human Activity Recognition,Deep Learning,Deep learning,3D Skeleton Data,Spatio-temporal Image Encoding,Sliding Window","Nassim Mokhtari,Alexis Nédélec,Pierre de Loor",2022
Evaluating Visual Cues for Future Airborne Surveillance Using Simulated Augmented Reality Displays,"This work explores the interaction between Augmented Reality (AR) and eye accommodation for airborne surveillance by simulating AR environments in Virtual Reality (VR). We simulate the AR display as displays with the capabilities needed for airborne surveillance are limited and because it would be hazardous to experiment directly on surveillance aircraft. While there is precedent for simulating AR in a VR environment\, our study account for two of the physical and physiological aspects of AR: we factor in the focal plane of the AR technology and simulate the eye accommodation reflex of the user to provide focus. We ran a study with 24 participants examining AR cues to support visual search. We also compare the effects of having secondary tasks (that surveillance operators are normally responsible for) directly on the observation window using AR. Our results show that the effectiveness of the AR cues is dependent on the modality of the secondary task. We also found that\, under certain situations\, operators’ performances for the search task are improved if the focal plane of the AR display is at the same distance as subsequent search targets.","Virtual Reality,Augmented Reality,Data Visualization,User Interfaces","Nicolas Barbotin,James Baumeister,Andrew Cunningham,Thierry Duval,Olivier Grisvard,Bruce Thomas",2022
Modèle multi-agent d’auto-organisation pour le butinage au sein d’une colonie d’abeilles,"Les Systèmes Multi-Agents (SMA) ont montré depuis plusieurs années leur adéquation à modéliser et simuler les systèmes complexes. Nous suivons cette approche pour modéliser une colonie d’abeilles située dans une ruche Dadant\, où plusieurs dizaines de milliers d’individus interagissent\, dans le but d’évaluer l’impact d’actions locales au niveau des abeilles (e.g. pratiques apicoles) sur la colonie. Nous nous concentrons ici sur l’activité de butinage\, en nous intéressant plus particulièrement au phénomène d’auto-organisation qui conduit les butineuses à sélectionner les meilleures sources de nourriture disponibles. Les interactions des butineuses avec l’environnement extérieur de la ruche\, qui diffère de l’intérieur en termes de granularité des actions et d’échelle\, sont simulées grâce à un module paramétrable et compatible agent\, en fonction de la météo et des sources de nourriture environnantes. Les résultats de deux expérimentations du modèle\, l’une sur une année complète\, et l’autre sur une journée\, montrent que le phénomène d’auto-organisation des butineuses résulte du comportement des butineuses et des mécanismes de recrutement implantés\, et offrent une première validation de notre modèle.,The agent-based approach has been successfully used in the past years to model and simulate complex systems. We use this approach on a honeybee colony in a Dadant hive\, where several tens of thousands of bees interact\, in order to evaluate the impact of local actions at the bee-level (such as beekeeping practices) on the global system. In this article\, we focus on the foraging activity\, its self-organisation mechanisms and the behaviour of foraging bees\, and how these bees interact with the environment of the hive\, greatly different in granularity and scale. We present a customizable\, agent-compliant module that aims at modelling and simulating the foraging\, according to the weather and the surrounding nectar sources. The results of two experimentations provide a first validation of our model\, showing that the agents’ behaviours lead to a self-organizing process of the best available sources’ selection.","Multiagent simulation,Self-organization,Environment,Complex Sys- tems,Simulation multi-agent,Auto-organisation,Systèmes Complexes,Environnement","Jérémy Rivière,Thomas Alves,Cédric Alaux,Yves Le Conte,Yves Layec,André Lozac’h,Frank Singhoff,Vincent Rodin",2022
"ARgus : système multi-vues pour collaborer à distance avec un utilisateur en réalité augmentée,ARgus: Multi-View System to Collaborate Remotely with an Augmented Reality User","ARgus permet une collaboration asymétrique entre un utilisateur portant un casque de réalité augmentée (RA) et un utilisateur distant muni d'un ordinateur standard. Ce système de communication vidéo combine trois représentations de l'espace de travail de l'utilisateur en réalité augmentée : une représentation virtuelle\, une vue à la première personne et une vue externe. ARgus propose aussi des outils interactifs permettant la navigation\, la pré-visualisation\, le pointage et l'annotation dans chacune de ces vues.,ARgus supports asymmetric collaboration between augmented-reality (AR) and remote desktop users. This video-mediated communication system combines three representations of the AR user's workspace: a fully virtual representation\, a first-person view\, and an external view. ARgus also includes interactive tools allowing navigation\, previewing\, pointing\, and annotation in these views.","Augmented reality,Remote collaboration,Video-mediated communication,Augmented video,Réalité augmentée,Collaboration à distance,Communication par vidéo,Vidéo augmentée","Arthur Fages,Cédric Fleury,Theophanis Tsandilas",2022
Characterization of collaboration in a virtual environment with gaze and speech signals,"Collaboration during the completion of complex tasks requires synchronization and effective communication within teams. In this paper\, we study multimodal collaboration metrics with the intention of designing collaboration support systems that enable the evaluation of collaboration quality. The goal is to provide real-time feedback and prevent the emergence of critical situations due to poor collaboration. We use a collaborative virtual environment to control the situation and the effects of the environment. As a first step to measure collaboration\, we present a work in progress that aims to test the effectiveness of verbal and gaze measurements as an indicator of collaboration quality. To do so\, an assembly task was performed by twelve dyads in our virtual environment. A tool was designed to process activity inputs in real time. Our findings show that verbal and gaze metrics can provide feedback on collaboration in virtual environment. Using these measures together with others would provide more accurate feedback on collaboration. Lastly\, suggestions for improving the tool and an interest for other collaboration indicators are raised.","Collaboration,Virtual reality,Collaboration cues,Joint visual attention,Turn-taking,Overlapped Speech","Aurélien Léchappé,Aurélien Milliat,Cédric Fleury,Mathieu Chollet,Cédric Dumas",2023
Deep weathering effects,"Weathering phenomena are ubiquitous in urban environments\, where it is easy to observe severely degraded old buildings as a result of water penetration. Despite being an important part of any realistic city\, this kind of phenomenon has received little attention from the Computer Graphics community compared to stains resulting from biological or flow effects on the building exteriors. In this paper\, we present physically-inspired deep weathering effects\, where the penetration of humidity (i.e.\, water particles) and its interaction with a building's internal structural elements result in large\, visible degradation effects. Our implementation is based on a particle-based propagation model for humidity propagation\, coupled with a spring-based interaction simulation that allows chemical interactions\, like the formation of rust\, to deform and destroy a building's inner structure. To illustrate our methodology\, we show a collection of deep degradation effects applied to urban models involving the creation of rust or of ice within walls.","Weathering,Rust,Bricks,Iron","Adrien Verhulst,Jean-Marie Normand,Guillaume Moreau,Gustavo Patow",2023
A unifying method-based classification of robot swarm spatial self-organisation behaviours,"Self-organisation in robot swarms can produce collective behaviours\, particularly through spatial self-organisation. For example\, it can be used to ensure that the robots in a swarm move collectively. However\, from a designer’s point of view\, understanding precisely what happens in a swarm that allows these behaviours to emerge at the macroscopic level remains a difficult task. The same behaviour can come from multiple different controllers (ie the control algorithm of a robot) and a single controller can give rise to multiple different behaviours\, sometimes caused by slight changes in self-organisation. To grasp the causes of these differences\, it is necessary to investigate the relationships between the many methods of self-organisation that exist and the various behaviours that can be obtained. The work presented here addresses self-organisation in robot swarms by focusing on the main behaviours that lead to spatial self-organisation of the robots. First\, we propose a unified definition of the different behaviours and present an original classification system highlighting ten self-organisation methods that each allow one or more behaviours to be performed. An analysis\, based on this classification system\, links the identified mechanisms with behaviours that could be considered as obtainable or not. Finally\, we discuss some perspectives on this work\, notably from the point of view of an operator or designer.","Swarm intelligence,Robot swarm,Self-organisation,Aggregation,Flocking,Coverage,Pattern formation,Shape formation","Aymeric Hénard,Jérémy Rivière,Etienne Peillard,Sébastien Kubicki,Gilles Coppin",2023
