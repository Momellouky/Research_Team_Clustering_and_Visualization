title_s,abstract_s,keyword_s,authFullName_s,publicationDateY_i,language_s
Acoustic-based fluency classification using LSTM-Attention with computationally-cheap data augmentation for an adaptive voicebot,"Most voicebots still ignore\, nowadays\, user fluency level\, although recognizing it would allow to give answers to adaptation issues\, according to the language level of the interlocutor. Towards to such an end\, this paper proposes a fluency classification model using a small audio dataset. We extract various features such as Mel-frequency cepstral coefficients (MFCC) from the audio. Using recent classification models\, such as CNN-LSTM-Attention and Wav2vec 2.0\, we propose fluency classification models through three usual categories (Low\, Intermediate and High). Furthermore\, we demonstrate that simple data augmentation methods can improve classification accuracy. We employ several simple data augmentation techniques\, such as speed and pitch scale variation. This augmentation multiplies by 6 the number of training samples when applied only to original samples\, and by 32 when also applied to augmented samples.","Language fluency level,CNN-LSTM,Voice conversational agent,Data augmentation","Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc",2023,en
"Computer Vision and Robot Navigation in 3D Environments","This dissertation presents contributions to research problems in the domains of computer vision and navigation in 3D environments for ground robots. Specifically\, Chapter 2 is dedicated to 3D vision and presents machine-learning based methodologies for the semantic understanding of geometric and color data\, for applications pertaining to digital libraries of 3D objects and semantic mapping of static or dynamic environments populated by humans and explored by robots. We contribute more robust and effective 3D perception methods inspired from the fields of novelty detection\, incremental learning and intelligent\, multi-modal data fusion. In the sequel\, Chapter 3 addresses the problem of safe and effective navigation of ground robots operating in 3D outdoor or indoor environments\, focusing on the negotiation of negative and positive obstacles by leveraging the power of robot learning via physics-based simulation. We establish a general framework for modeling robot traversability in 3D terrains that is instantiated to the motion control of articulated\, tracked robot manipulators. Diverse motion control behaviors are developed for the purpose of staircase ascent/descent\, gap traversal up to socially-compliant navigation\, leveraging on advances in the fields of reinforcement learning\, end-to-end learning and potential fields. Finally\, Chapter 4 describes the deployment of terrestrial robots from a system engineering perspective in the context of in-field experiments and Chapter 5 unfolds future research directions.","Object recognition,Obstacle negotiation,Unmanned ground vehicles,Robot learning",Panagiotis Papadakis,2023,en
Commonsense Reasoning for Identifying and Understanding the Implicit Need of Help and Synthesizing Assistive Actions,"Human-Robot Interaction (HRI) is an emerging subfield of service robotics. While most existing approaches rely on explicit signals (i.e. voice\, gesture) to engage\, current literature is lacking solutions to address implicit user needs. In this paper\, we present an architecture to (a) detect user implicit need of help and (b) generate a set of assistive actions without prior learning. Task (a) will be performed using state-of-the-art solutions for Scene Graph Generation coupled to the use of commonsense knowledge; whereas\, task (b) will be performed using additional commonsense knowledge as well as a sentiment analysis on graph structure. Finally\, we propose an evaluation of our solution using established benchmarks (e.g. ActionGenome dataset) along with human experiments. The main motivation of our approach is the embedding of the perception-decision-action loop in a single architecture.","Commonsense Reasoning,Knowledge Graph,Vision-to-Language,Cognitive Robotics,Sentiment Analysis,Scene Graph Generation","Maëlic Neau,Paulo Santos,Anne-Gwenn Bosser,Nathan Beu,Cédric Buche",2022,en
Human Model For Industrial System And Product Design In Industry 5.0: A Case Study,"Human performance models can be included in industrial system models to improve the design of the industrial system\, manufacturing processes\, and product design. In our use case\, a critical process in the production of a new airplane was being considered for automation. This process requires the highest quality assurance and is normally performed manually. Robot assistance could improve quality and efficiency. A human performance model focused on worker fatigue was developed\, taking into account characteristics of the workers\, robots\, and tasks. Two different automation scenarios (fully manual\, semi-automated)\, with different worker characteristics such as skill\, age\, motivation\, etc. were studied. Using historical production line data in the fully manual scenario\, and simulated data for the semi-automated scenario\, global fatigue scores and graphical visualization were generated by the model for each scenario\, allowing the system architects to understand the effects of the future production system on workers\, including errors\, time lost\, costs and overall resilience of the system.","Industry 50,Production and manufacturing,Simulation model,Worker fatigue","Arnaud Allemang--Trivalle,Jérémie Donjat,Gaëlic Béchu,Gilles Coppin,Oliver W. Klaproth,Andreas Mitschke,Arnd Schirrmann,Mathieu Chollet,Caroline Gl Cao",2023,en
An Open-Source Software Framework for Reinforcement Learning-based Control of Tracked Robots in Simulated Indoor Environments,"A simulation framework based on the open-source robotic software Gazebo and the Robot Operating System (ROS) is presented for articulated tracked robots\, designed for reinforcement learning-based (RL) control skill acquisition. In particular\, it is destined to serve as a research tool in the development and evaluation of methods in the domain of mobility learning for articulated tracked robots\, in 3D indoor environments. Its architecture allows to interchange between different RL libraries and algorithm implementations\, while learning can be customized to endow specific properties within a control skill. To demonstrate its utility\, we focus on the most demanding case of staircase ascent and descent using depth image data\, while respecting safety via reward function shaping and incremental\, domain randomization-based\, end-to-end learning.","Reinforcement learning,Robot control,Incremental learning,Domain randomizaion,Staircase negotiation,Tracked robots","A Mitriakov,Panagiotis Papadakis,Serge Garlatti",2022,en
Convolutional Neural Network Bootstrapped by Dynamic Segmentation and Stigmergy-Based Encoding for Real-Time Human Activity Recognition in Smart Homes,"Recently\, deep learning (DL) approaches have been extensively employed to recognize human activities in smart buildings\, which greatly broaden the scope of applications in this field. Convolutional neural networks (CNN)\, well known for feature extraction and activity classification\, have been applied for estimating human activities. However\, most CNN-based techniques usually focus on divided sequences associated to activities\, since many real-world employments require information about human activities in real time. In this work\, an online human activity recognition (HAR) framework on streaming sensor is proposed. The methodology incorporates real-time dynamic segmentation\, stigmergy-based encoding\, and classification with a CNN2D. Dynamic segmentation decides if two succeeding events belong to the same activity segment or not. Then\, because a CNN2D requires a multi-dimensional format in input\, stigmergic track encoding is adopted to build encoded features in a multi-dimensional format. It adopts the directed weighted network (DWN) that takes into account the human spatio-temporal tracks with a requirement of overlapping activities. It represents a matrix that describes an activity segment. Once the DWN for each activity segment is determined\, a CNN2D with a DWN in input is adopted to classify activities. The proposed approach is applied to a real case study: the “Aruba” dataset from the CASAS database.","Real-time human activity recognition convolutional neural network directed weighted network overlapping activities,Real-time human activity recognition,Convolutional neural network,Directed weighted network,Overlapping activities","Houda Najeh,Christophe Lohr,Benoit Leduc",2023,en
From sparse SLAM to dense mapping for UAV autonomous navigation,"Autonomous or semi-autonomous navigation of UAVs is of great interest in the Defense and Security domains\, as it significantly improves their efficiency and responsiveness during operations. The perception of the environment and in particular the dense and metric 3D mapping in real time is a priority for navigation and obstacle avoidance. We therefore present our strategy to jointly estimate a dense 3D map by combining a sparse map estimated by a state-of-the-art Simultaneous Localization and Mapping (SLAM) system and a dense depth map predicted by a monocular self-supervised method. Then\, a lightweight and volumetric multi-view fusion solution is used to build and update a voxel map.","Usar,Monocular depth prediction,Deep Learning,Drones,3D mapping","Yassine Habib,Panagiotis Papadakis,Antoine Fagette,Cédric Le Barz,Tiago Gonçalves,Cédric Buche",2023,en
AGOD-Grasp: an Automatically Generated Object Dataset for benchmarking and training robotic grasping algorithms,"Robust robotic grasping of objects has broad industrial applications. The reliability of data-driven grasping methods is influenced by the variability of object shapes encountered during training. Most existing objects datasets suffer from human selection bias\, lack variability\, or are non-reproducible. This paper presents a physically reproducible 3D-printable object dataset for training and evaluating grasping algorithms. It contains exact 3D meshes of 50 objects for simulation and printing purposes. The various objects in the dataset were found using the MAP-Elites algorithm\, optimising the variability of objects according to two grasping metrics. We used a Variational AutoEncoder (VAE) as a generative model for voxelgrid object models\, which were then converted to meshes and simplified using Volumetric Hierarchical Approximate Convex Decomposition (V-HACD). The dataset is publicly available online\, and can be ordered from any 3d-printing service according to given specifications. We hope it will become a standard benchmarking dataset for the robotic grasping community.","Grasping object set,Data-driven grasping,Robotic grasping,Dataset,Data Sets for Robot Learning,Performance Evaluation and Benchmarking,Grasping","Mihai Andries,Yoann Fleytoux,Serena Ivaldi,J.-B. Mouret",2023,en
"Metric\, dense and real-time 3D Reconstruction for drone autonomous navigation","Simultaneous Localization And Mapping (SLAM) research have reach maturity allowing state of the art algorithm to build a 3D dense and metric reconstruction in real-time. However\, it becomes more challenging in drone navigation context where we favor passive sensors in monocular configuration and need to tackle fast motions or illumination changes. Research on Deep learning monocular depth estimation and event cameras present interesting advances to resolve these challenges.","SLAM,3D reconstruction,VIO,Semantic mapping,Deep Learning,Depth estimation,Event camera","Yassine Habib,Panagiotis Papadakis,Cédric Le Barz,Cédric Buche,Antoine Fagette",2021,en
Goal Space Abstraction in Hierarchical Reinforcement Learning via Reachability Analysis,"Open-ended learning benefits immensely from the use of symbolic methods for goal representation as they offer ways to structure knowledge for efficient and transferable learning. However\, the existing Hierarchical Reinforcement Learning (HRL) approaches relying on symbolic reasoning are often limited as they require a manual goal representation. The challenge in autonomously discovering a symbolic goal representation is that it must preserve critical information\, such as the environment dynamics. In this work\, we propose a developmental mechanism for subgoal discovery via an emergent representation that abstracts (i.e.\, groups together) sets of environment states that have similar roles in the task. We create a HRL algorithm that gradually learns this representation along with the policies and evaluate it on navigation tasks to show the learned representation is interpretable and results in data efficiency.",,"Mehdi Zadem,Sergio Mover,Sao Mai Nguyen",2023,en
Guest Editorial Special Issue on Continual Unsupervised Sensorimotor Learning,"The pursuit of higher levels of autonomy and versatility in robotics is arguably led by two main factors. First, as we push robots out of the labs and production lines, it becomes increasingly challenging to design for all possible scenarios that a particular robot might encounter. Second, the cost of designing, manufacturing, and maintaining such systems becomes prohibitive.","Special issues and sections,Robot sensing systems,Robots,Reinforcement learning,Unsupervised learning","Nicolas Navarro-Guerrero,Sao Mai Nguyen,Erhan Oztop,Junpei Zhong",2021,en
"Human activity recognition in smart homes : tackling data variability using context-dependent deep learning\, transfer learning and data synthesis","The smart home is at the center of attention for the many innovative applications and services it can offer in terms of security\, energy savings\, comfort improvement and health support. The last few years have seen the emergence of a multitude of techniques and approaches through the artificial intelligence to bring the backbone of all these services to the home; the ability to understand the lifestyle and activities of its residents through home automation sensors. Despite advances in deep learning and the increase in the amount of data\, these methods do not generalize and fully address the complexity and variability of human activity. Moreover\, the use and the application of these approaches in a real\, industrial and commercial context remains a major challenge due to the lack of labeled data from the destination environment. This thesis proposes to try to improve these methods and their portability through the understanding of the activation context of home automation sensors and the transfer of knowledge by drawing inspiration from Natural Language Processing techniques\, and through data synthesis via the Digital Twin concept.","Human activity recognition,Smart homes,Context-Dependent deep learning,Transfer learning,Data synthesis,Digital twin,",Damien Bouchabou,2022,en
Intrinsically Motivated Open-Ended Multi-Task Learning Using Transfer Learning to Discover Task Hierarchy,"In open-ended continuous environments\, robots need to learn multiple parameterised control tasks in hierarchical reinforcement learning. We hypothesise that the most complex tasks can be learned more easily by transferring knowledge from simpler tasks\, and faster by adapting the complexity of the actions to the task. We propose a task-oriented representation of complex actions\, called procedures\, to learn online task relationships and unbounded sequences of action primitives to control the different observables of the environment. Combining both goal-babbling with imitation learning\, and active learning with transfer of knowledge based on intrinsic motivation\, our algorithm self-organises its learning process. It chooses at any given time a task to focus on; and what\, how\, when and from whom to transfer knowledge. We show with a simulation and a real industrial robot arm\, in cross-task and cross-learner transfer settings\, that task composition is key to tackle highly complex tasks. Task decomposition is also efficiently transferred across different embodied learners and by active imitation\, where the robot requests just a small amount of demonstrations and the adequate type of information. The robot learns and exploits task dependencies so as to learn tasks of every complexity.","Curriculum learning,Continual learning,Hierarchical reinforcement learning,Interactive reinforcement learning,Imitation learning,Active imitation learning,Multi-task learning,Intrinsic motivation","Nicolas Duminy,Sao Mai Nguyen,Junshuai Zhu,Dominique Duhaut,Jerome Kerdreux",2021,en
Improving Reward Estimation in Goal-Conditioned Imitation Learning with Counterfactual Data and Structural Causal Models,"Imitation learning has emerged as a pragmatic alternative to reinforcement learning for teaching agents to execute specific tasks\, mitigating the complexity associated with reward engineering. However\, the deployment of imitation learning in real-world scenarios is hampered by numerous challenges. Often\, the scarcity and expense of demonstration data hinder the effectiveness of imitation learning algorithms. In this paper\, we present a novel approach to enhance the sample efficiency of goal-conditioned imitation learning. Leveraging the principles of causality\, we harness structural causal models as a formalism to generate counterfactual data. These counterfactual instances are used as additional training data\, effectively improving the learning process. By incorporating causal insights\, our method demonstrates its ability to improve imitation learning efficiency by capitalizing on generated counterfactual data. Through experiments on simulated robotic manipulation tasks\, such as pushing\, moving\, and sliding objects\, we showcase how our approach allows for the learning of better reward functions resulting in improved performance with a limited number of demonstrations\, paving the way for a more practical and effective implementation of imitation learning in real-world scenarios.","Imitation Learning,Causality,Structural Causal Models,Counterfactual Reasoning","Mohamed Khalil Jabri,Panagiotis Papadakis,Ehsan Abbasnejad,Gilles Coppin,Javen Shi",2023,en
Dynamic Segmentation of Sensor Events for Real-Time Human Activity Recognition in a Smart Home Context,"Human activity recognition (HAR) is fundamental to many services in smart buildings. However\, providing sufficiently robust activity recognition systems that could be confidently deployed in an ordinary real environment remains a major challenge. Much of the research done in this area has mainly focused on recognition through pre-segmented sensor data. In this paper\, real-time human activity recognition based on streaming sensors is investigated. The proposed methodology incorporates dynamic event windowing based on spatio-temporal correlation and the knowledge of activity trigger sensor to recognize activities and record new events. The objective is to determine whether the last event that just happened belongs to the current activity\, or if it is the sign of the start of a new activity. For this\, we consider the correlation between sensors in view of what can be seen in the history of past events. The proposed algorithm contains three steps: verification of sensor correlation (SC)\, verification of temporal correlation (TC)\, and determination of the activity triggering the sensor. The proposed approach is applied to a real case study: the “Aruba” dataset from the CASAS database. F1 score is used to assess the quality of the segmentation. The results show that the proposed approach segments several activities (sleeping\, bed to toilet\, meal preparation\, eating\, housekeeping\, working\, entering home\, and leaving home) with an F1 score of 0.63–0.99.","Real-time human activity recognition,Dynamic segmentation,Smart building,Event correlation,Temporal correlation,Triggering sensor","Houda Najeh,Christophe Lohr,Benoit Leduc",2022,en
Digital Twin Driven Smart Home: A Feasibility Study,"We aim to facilitate the daily-life activities of frail or elderly people in collaboration with mobile assistive robots through the means of a digital twin-powered smart home. Being able to quickly and efficiently produce a digital twin of the human user's environment\, can help to further develop personalized assistive solutions. As our first investigation toward this goal\, we describe our proof-of-concept ""digital twindriven smart home"" implementation. It consists of a virtual representation\, robot navigation and environment semantics using open-source software. The initial obtained results on the building process of the digital twin are encouraging and suggest the possibility of integration of digital twin for smart spaces.","Ambient assisted living,Cyber physical system,Living-lab,Semantics","Alireza Asvadi,Andrei Mitriakov,Christophe Lohr,Panagiotis Papadakis",2022,en
Real-Time Human Activity Recognition in Smart Home on Embedded Equipment: New Challenges,"Building Energy Management (BEM) and monitoring systems should not only consider HVAC systems and building physics but also human behaviors. These systems could provide information and advice to occupants about the significance of their practices with regard to the current state of a dwelling. It is also possible to provide services such as assistance to the elderly\, comfort and health monitoring. For this\, an intelligent building must know the daily activities of its residents and the algorithms of the smart environment must track and recognize the activities that the occupants normally perform as part of their daily routine. In the literature\, deep learning is one of effective supervised learning model and cost-efficient for real-time HAR\, but it still struggles with the quality of training data (missing values in time series and non-annotated event)\, the variability of data\, the data segmentation and the ontology of activities. In this work\, recent research works\, existing algorithms and related challenges in this field are firstly highlighted. Then\, new research directions and solutions (performing fault detection and diagnosis for drift detection\, multi-label classification modeling for multi-occupant classification\, new indicators for training data quality\, new metrics weighted by the number of representations in dataset to handle the issue of missing data and finally language processing for complex activity recognition) are suggested to solve them respectively and to improve this field.","Real-time human activity recognition,Deep learning,Smart home,Sensors,Embedded equipments","Houda Najeh,Christophe Lohr,Benoit Leduc",2022,en
Towards supervised real-time human activity recognition on embedded equipment,"In recent years\, real-time human activity recognition (HAR) has reached importance due to its applications in various domains such as assistive services for the elderly in smart buildings\, monitoring\, well-being\, comfort and security. Various techniques\, researched within the image processing and computer vision communities\, have been established to recognize human activities in real-time\, but all of them are based on wearable sensors and there is no much attention for ambient sensor based approaches. In the literature\, deep learning (DL) is one of effective and cost-efficient supervised learning model and different architectures haves been investigated for real-time HAR. However\, it still struggles with the quality of data as well as hardware implementation issues. This paper presents two contributions. Firstly\, an intensive analysis of DL architectures and its characteristics along with their limitations in the framework of real time HAR are investigated. Secondly\, existing hardware architectures and related challenges in this field are highlighted (adaptation of DL architectures towards microcontrollers\, difficulty to provide a smart home with numerous sensors and trends regarding cloud-bases approaches). Then\, new research directions and solutions around the real-time data quality assessment\, the study of main performance factors for DL on microcontrollers\, the concept of minimal sensors set up for the employment of IoT devices and the distributed intelligence are suggested to solve them respectively and to improve this field.","Smart building,Real time human activity recognition,Deep learning,Software and hardware architectures,Edge computing","Houda Najeh,Christophe Lohr,Benoit Leduc",2022,en
Attenuating Catastrophic Forgetting by Joint Contrastive and Incremental Learning,"In class incremental learning\, discriminative models are trained to classify images while adapting to new instances and classes incrementally. Training a model to adapt to new classes without total access to previous class data\, however\, leads to the known problem of catastrophic forgetting of the previously learnt classes. To alleviate this problem\, we show how we can build upon recent progress on contrastive learning methods. In particular\, we develop an incremental learning approach for deep neural networks operating both at classification and representation level which alleviates forgetting and learns more general features for data classification. Experiments performed on several datasets demonstrate the superiority of the proposed method with respect to well known state-of-the-art methods.",,"Quentin Ferdinand,Benoit Clement,Quentin Oliveau,Gilles Le Chenadec,Panagiotis Papadakis",2022,en
"Dense\, metric and real-time 3D reconstruction for autonomous drone navigation","The navigation of small drones within an unknown area requires perception and analysis of their surrounding environments\, especially in GNSS-denied regions. A way to achieve this is by reconstructing a 3D dense metric map in real time. It allows the drone to localize itself\, plan its trajectory and to be aware of potential static and dynamic obstacles. Visual Inertial Odometry (VIO) algorithms focus on robot localization and trajectory\, while Simultaneous Localization and Mapping (SLAM) maintains both localization and mapping. These types of algorithms seem to have reached maturity\, and now face new challenges related to real applications in robotics. Studies are now towards robustness and efficiency through new sensors and Deep Learning (DL).",,"Yassine Habib,Panagiotis Papadakis,Cédric Buche,Cédric Le Barz,Antoine Fagette",2021,en
Technical Feasibility of Supervision of Stretching Exercises by a Humanoid Robot Coach for Chronic Low Back Pain: The R-COOL Randomized Trial,"Adherence to exercise programs for chronic low back pain (CLBP) is a major issue. The R-COOL feasibility study evaluated humanoid robot supervision of exercise for CLBP. Aims are as follows: (1) compare stretching sessions between the robot and a physiotherapist (control)\, (2) compare clinical outcomes between groups\, and (3) evaluate participant perceptions of usability and satisfaction and therapist acceptability of the robot system. Prospective\, randomized\, controlled\, single-blind\, 2-centre study comparing a 3-week (3 hours/day\, 5 days/week) physical activity program. Stretching sessions (30 minutes/day) were supervised by a physiotherapist (control) or the robot. Primary outcome: daily physical activity time (adherence). Secondary outcomes: lumbar pain\, disability and fear and beliefs\, participant perception of usability (system usability scale) and satisfaction\, and physiotherapist acceptability (technology acceptance model). Clinical outcomes were compared between groups with a Student t -test and perceptions with a Wilcoxon test. Data from 27 participants were analysed ( n = 15 control and n = 12 robot group). Daily physical activity time did not differ between groups\, but adherence declined (number of movements performed with the robot decreased from 82% in the first week to 72% in the second and 47% in the third). None of the clinical outcomes differed between groups. The median system usability scale score was lower in the robot group: 58 (IQR 11.8) points vs. 87 (IQR 9.4) in the control group at 3 weeks ( p < 0.001 ). Median physiotherapist rating of the technology acceptance model was <3 points\, suggesting a negative opinion of the robot. In conclusion\, adherence to robot exercise reduced over time; however\, lumbar pain\, disability\, or fear and beliefs did not differ between groups. The results of the participant questionnaires showed that they were willing to use such a system\, although several technical issues suggested the KERAAL system could be improved to provide fully autonomous supervision of physical activity sessions.",,"Agathe Blanchard,Sao Mai Nguyen,Maxime Devanne,Mathieu Simonnet,Myriam Le Goff-Pronost,Olivier Rémy-Néris",2022,en
Management of Human-Cobot Interaction for the Execution of Tasks in the Kitchen,"The development of robotics has opened up prospects in the field of personal assistance, allowing for the extension of the autonomy of individuals with disabilities. Individuals with physical disabilities retain their intellectual faculties and can be autonomous in their daily lives, provided they have technical means compensating for their disability, such as robotic devices. The main issue addressed in this article is the management of interaction between humans (with disabilities) and cobots (collaborative robots) at home in a meal preparation assistance scenario. Defining the interaction model facilitates the choice of architecture and system composition. The system consists of a control level that manages the system and an executive level that executes the gesture. The former is a multi-agent system that controls cobots and other equipment, such as sensors and actuators present in the automated kitchen. The second system is the mechanism that constitutes the cobot.","Interaction,Assistant Roobot,Multi-agent system,Cobot,ROS,JADE","Samia Benferhat,Florent Frizon de Lamotte,Christophe Lohr,Jean-Luc Philippe",2021,fr
"Evaluating Kinect\, OpenPose and BlazePose for Human Body Movement Analysis on a Low Back Pain Physical Rehabilitation Dataset","Analyzing human motion is an active research area, with various applications. In this work, we focus on human motion analysis in the context of physical rehabilitation using a robot coach system. Computer-aided assessment of physical rehabilitation entails evaluation of patient performance in completing prescribed rehabilitation exercises, based on processing movement data captured with a sensory system, such as RGB and RGB-D cameras. As 2D and 3D human pose estimation from RGB images had made impressive improvements, we aim to compare the assessment of physical rehabilitation exercises using movement data obtained from both RGB-D camera (Microsoft Kinect) and estimation from RGB videos (OpenPose and BlazePose algorithms). A Gaussian Mixture Model (GMM) is employed from position (and orientation) features, with performance metrics defined based on the log-likelihood values from GMM. The evaluation is performed on a medical database of clinical patients carrying out low back-pain rehabilitation exercises, previously coached by robot Poppy.","motion assessment, human skeleton representation, robot coach, humanoid robot, human body movement analysis, physical rehabilitation","Aleksa Marusic,Sao Mai Nguyen,Adriana Tapus",2023,en
"Perspectives d'apport du projet PRIM dans le domaine du handicap,PRIM project: what contributions for disabilities?","In the PRIM project\, we aim at giving people the power to create scenagrams (interaction scenarios between a human and digital devices) without the need to learn programming or to ask for computer scientists. In this project\, software design follows an unconventional approach\, far from classical codes\, to embody human thinking (based on interactions) instead of computer logic (based on algorithms). The main idea rests on a new time representation using a PRIM-specific timeline instead of a standardized timeline. We evaluated acceptability and cognitive compatibility of this new timeline with 50 participants. Results are very promising. In this paper\, we detail qualitative evaluation results about the interest of such software in the field of disability.","Timeline metaphor,Software,Programmation for all,Scenagram","Céline Jost,Justin Debloos,Agnès Piquard-Kipffer,Caroline Barbot-Bouzit,Brigitte Le Pevedic",2022,fr
Considering the mutual information criterion for sensor configuration selection in human activity recognition in smart homes,"Ambient sensors of a smart home offer new services to occupants related to security\, comfort and energy management. This makes it possible to estimate the practices of the occupants and determine energy consumption\, by estimating the number of occupants per zone\, their activities and routines\, with a requirement for digital sobriety (i.e fewer sensors possible\, but enough to ensure a service). The selection of a pertinent sensor configuration is an important aspect in human activity recognition (HAR). This problem includes the selection of the number and type of the sensors\, as well as the identification of the most informative ones. In this paper\, we propose a novel approach to determine the most informative sensor types (among motion detection sensors and door contact sensors) based on the criterion of mutual information. The selected configuration of sensors is applied to recognize daily activities in real-time in a real-world dataset: Aruba\, from the CASAS project. The simulation results show good performance of classification and a save of processing time. Highlights • Consider the mutual information criterion to select the minimum setup of sensors • Recognize human activities in real-time with the selected setup of sensors. • Save of the processing time with a minimum setup of sensors.",,"Houda Najeh,Christophe Lohr,Benoit Leduc",2023,en
"Large-scale deep class-incremental learning","Incremental learning (IL) enables the adaptation of artificial agents to dynamic environments in which data is presented in streams. This type of learning is needed when access to past data is limited or impossible but is affected by catastrophic forgetting. This phenomenon consists of a drastic performance drop for previously learned information when ingesting new data. One way to tackle this problem is to use a limited memory of the past to refresh previously learned knowledge. Currently\, memory-based approaches achieve the best state-of-the-art results. In this thesis\, we present many methods with and without memory of the past. Our methods deal with catastrophic forgetting either by (1) calibrating past and new classes scores at the end of the network\, or (2) performing initial class weights replay\, or (3) transferring knowledge between reference and target datasets. We notably investigate the usefulness of the widely used knowledge distillation and the effect of enabling or not a memory of the past. Extensive experiments against a range of state-of-the-art approaches were conducted in order to validate the efficiency of our methods.","Incremental learning,Catastrophic forgetting,Image classification,Convolutionel neural networks",Eden Belouadah,2021,en
"RoboCup@Home Education 2020 Best Performance: RoboBreizh\, a modular approach","Every year\, the Robocup@Home competition challenges teams and robots' abilities. In 2020\, the RoboCup@Home Education challenge was organized online\, altering the usual competition rules. In this paper\, we present the latest developments that lead the RoboBreizh team to win the contest. These developments include several modules linked to each other allowing the Pepper robot to understand\, act and adapt itself to a local environment. Up-to-date available technologies have been used for navigation and dialogue. First contribution includes combining object detection and pose estimation techniques to detect user's intention. Second contribution involves using Learning by Demonstrations to easily learn new movements that improve the Pepper robot's skills. This proposal won the best performance award of the 2020 RoboCup@Home Education challenge.",,"Antoine Dizet,Cédric Le Bono,Amélie Legeleux,Maëlic Neau,Cédric Buche",2021,en
Gaussian Mixture Model with Weighted Data for Learning by Demonstration,"Cobots are robots specialized in collaborating with a human to do a task. These cobots needs to be easily re-programmed in order to adapt to a new task. Learning by Demonstration enables a non-expert user to program a cobot by demonstrating how to realize the task. Once the learning is done\, the user can only improve the learning by adding new demonstrations or deleting existing ones. In this article\, the proposed model gives the possibility to the user to impact the learning by choosing which parts of the demonstration has more importance. This model uses an extended version of Gaussian Mixture Model (GMM) with weighted data coupled with Gaussian Mixture Regression (GMR). This architecture was tested with two different tasks and with two robots. Results indicate better generated trajectory with the proposed approach.",,"Amélie Legeleux,Cédric Buche,Dominique Duhaut",2022,en
"ScenaProd: tool to create multisensorial exercises IHM ’22 Conference","This demonstration aims at presenting ScenaProd\, a tool that allows people to develop multisensory exercises. All participants will be able to create their own multisensory exercise with that tool. They will also have the possibility to test a more complete exercise that will already have been created. A multisensory exercise can be defined as an interaction between a human being and different devices. For example\, a robot asks a question while displaying a visual clue on a screen. Then\, the participant can respond by pressing a large and colored contactor. In case of a correct answer\, the robot would play a short victory song and a light would light up green. If a wrong answer were given\, the system would have a different reaction.","Scenagramme,Visual programming language,Multisensory experience","Justin Debloos,Celine Jost,Brigitte Le Pévédic,Gérard Uzan",2022,fr
A comparative study of calibration methods for imbalanced class incremental learning,"Deep learning approaches are successful in a wide range of AI problems and in particular for visual recognition tasks. However\, there are still open problems among which is the capacity to handle streams of visual information and the management of class imbalance in datasets. Existing research approaches these two problems separately while they co-occur in real world applications. Here\, we study the problem of learning incrementally from imbalanced datasets. We focus on algorithms which have a constant deep model complexity and use a bounded memory to store exemplars of old classes across incremental states. Since memory is bounded\, old classes are learned with fewer images than new classes and an imbalance due to incremental learning is added to the initial dataset imbalance. A score prediction bias in favor of new classes appears and we evaluate a comprehensive set of score calibration methods to reduce it. Evaluation is carried with three datasets\, using two dataset imbalance configurations and three bounded memory sizes. Results show that most calibration methods have beneficial effect and that they are most useful for lower bounded memory sizes\, which are most interesting in practice. As a secondary contribution\, we remove the usual distillation component from the loss function of incremental learning algorithms. We show that simpler vanilla fine tuning is a stronger backbone for imbalanced incremental learning algorithms.",,"Umang Aggarwal,Adrian Popescu,Eden Belouadah,Céline Hudelot",2021,en
Robot Manipulation Learning Using Generative Adversarial Imitation Learning,"Imitation learning allows learning complex behaviors given demonstrations. Early approaches belonging to either Behavior Cloning or Inverse Reinforcement Learning were however of limited scalability to complex environments. A more promising approach termed as Generative Adversarial Imitation Learning tackles the imitation learning problem by drawing a connection with Generative Adversarial Networks. In this work\, we advocate the use of this class of methods and investigate possible extensions by endowing them with global temporal consistency\, in particular through a contrastive learning based approach.",,Mohamed Khalil Jabri,2021,en
Robots Learn Increasingly Complex Tasks with Intrinsic Motivation and Automatic Curriculum Learning,"Multi-task learning by robots poses the challenge of the domain knowledge: complexity of tasks\, complexity of the actions required\, relationship between tasks for transfer learning. We demonstrate that this domain knowledge can be learned to address the challenges in life-long learning. Specifically\, the hierarchy between tasks of various complexities is key to infer a curriculum from simple to composite tasks. We propose a framework for robots to learn sequences of actions of unbounded complexity in order to achieve multiple control tasks of various complexity. Our hierarchical reinforcement learning framework\, named SGIM-SAHT\, offers a new direction of research\, and tries to unify partial implementations on robot arms and mobile robots. We outline our contributions to enable robots to map multiple control tasks to sequences of actions: representations of task dependencies\, an intrinsically motivated exploration to learn task hierarchies\, and active imitation learning. While learning the hierarchy of tasks\, it infers its curriculum by deciding which tasks to explore first\, how to transfer knowledge\, and when\, how and whom to imitate.",,"Sao Mai Nguyen,Nicolas Duminy,Alexandre Manoury,Dominique Duhaut,Cédric Buche",2021,en
Prerequisite structure discovery for an intelligent tutoring system based on intrinsic motivation,"This paper addresses the importance of Knowledge Structure (KS) and Knowledge Tracing (KT) in improving the recommendation of educational content in intelligent tutoring systems. The KS represents the relations between different Knowledge Components (KCs)\, while KT predicts a learner's success based on her past history. The contribution of this research includes proposing a KT model that incorporates the KS as a learnable parameter\, enabling the discovery of the underlying KS from learner trajectories. The quality of the uncovered KS is assessed by using it to recommend content and evaluating the recommendation algorithm with simulated students.","Intelligent Tutoring Systems,Knowledge Tracing,Knowledge Structure Discovery","Louis Annabi,Sao Mai Nguyen",2023,en
Reducing domain shift in synthetic data augmentation for semantic segmentation of 3D point clouds,"The use of deep learning in semantic segmentation of point clouds enables a drastic improvement of segmentation precision. However\, available datasets are restrained to a few applications with limited applicability to other fields. Using synthetic and real data can alleviate the burden of creating a dedicated dataset at the cost of domain-shift that is mostly addressed during training\, while treating the problem directly on the data has been less explored. Towards this goal\, two methods to alleviate domain shift are proposed\, firstly by enhanced generation and sampling of synthetic data and secondly by leveraging color information of unlabeled point clouds to color synthetic\, uncoloured data. Obtained results confirm their usefulness in improving semantic segmentation result (+3.43 into mIoU for a network trained on S3DIS zone 1). More importantly\, the devised coloring method shows the ability of a point-based network to link color information with recurrent geometric features. Finally\, the presented methods are able to bridge the domain-shift gap even in cases where inclusion of raw synthetic data during training impedes learning.",,"Romain Cazorla,Line Poinel,Panagiotis Papadakis,Cédric Buche",2022,en
"A Survey of Human Activity Recognition in Smart Homes Based on IoT Sensors Algorithms: Taxonomies\, Challenges\, and Opportunities with Deep Learning","Recent advances in Internet of Things (IoT) technologies and the reduction in the cost of sensors have encouraged the development of smart environments\, such as smart homes. Smart homes can offer home assistance services to improve the quality of life\, autonomy and health of their residents\, especially for the elderly and dependent. To provide such services\, a smart home must be able to understand the daily activities of its residents. Techniques for recognizing human activity in smart homes are advancing daily. But new challenges are emerging every day. In this paper\, we present recent algorithms\, works\, challenges and taxonomy of the field of human activity recognition in a smart home through ambient sensors. Moreover\, since activity recognition in smart homes is a young field\, we raise specific problems\, missing and needed contributions. But also propose directions\, research opportunities and solutions to accelerate advances in this field.","Smart Home,Deep Learning,Ambient Assisting Living,Smart Homes,Deep Learning DL,Human Activity Recognition,Taxonomies,Challenges,Opportunities,Survey,Artificial Intelligence AI,IoT - Internet of Things,Activities of daily living ADL,Smart Home","Damien Bouchabou,Sao Mai Nguyen,Christophe Lohr,Benoit Leduc,Ioannis Kanellos",2021,en
"Reinforcement learning-based control for safe 3D navigation of articulated tracked robot manipulators","Object transportation by an assistive tracked robot equipped with an arm constitutes a way to palliate the autonomy loss of people suffering from cognitive or motor impairments. As previous research works rely on conventional control to perform 3D navigation\, they lack generalization and portability to different robots or environments. Reinforcement learning (RL) based control is a less supervised alternative\, based on less restrictive assumptions on the knowledge of the robot dynamics or the structure of the environment. This thesis proposes a 3D navigation solution based on RL that uses all degrees of freedom of a robot. In particular\, we contribute to the formalization and the treatment of the staircase negotiation problem for ascent and descent with arm control. We analyze the portability of the solution to different robots and perform a demonstration of the transfer of controllers on a real robot. Finally\, we have developed and made available a software environment for learning indoor 3D navigation\, capable of performing end-to-end control learning in an incremental manner.","Reinforcement learning,Mobile robotics,Tracked robots,Safe control,",Andrei Mitriakov,2022,en
Temporal Alignment and Demonstration Selection as Pre-Processing Phase for Learning by Demonstration,"Robots can benefit from users’ demonstrations to learnmotions. To be efficient\, a pre-processing phase needsto be performed on data recorded from demonstrations.This paper presents pre-processing methods developedfor Learning By Demonstration (LbD). Thepre-processing phase consists in methods composedof alignment algorithms and algorithms that select thegood demonstrations. In this paper we propose sixmethods and compare them to select the best one.","Learning by Demonstration, Data Pre-processing, Robotics, Temporal Alignment","Jérémie Donjat,Amélie Legeleux,Cédric Buche,Dominique Duhaut",2022,en
Bottleneck Identification to Semantic Segmentation of Industrial 3D Point Cloud Scene via Deep Learning,"Point cloud acquisition techniques are an essential tool for the digitization of industrial plants\, yet the bulk of a designer's work remains manual. A first step to automatize drawing generation is to extract the semantics of the point cloud. Towards this goal\, we investigate the use of deep learning to semantically segment oil and gas industrial scenes. We focus on domain characteristics such as high variation of object size\, increased concavity and lack of annotated data\, which hampers the use of conventional approaches. To address these issues\, we advocate the use of synthetic data\, adaptive downsampling and context sharing.",,"Romain Cazorla,Line Poinel,Panagiotis Papadakis,Cédric Buche",2021,en
Using Language Model to Bootstrap Human Activity Recognition Ambient Sensors Based in Smart Homes,"Long Short Term Memory (LSTM)-based structures have demonstrated their efficiency for daily living recognition activities in smart homes by capturing the order of sensor activations and their temporal dependencies. Nevertheless\, they still fail in dealing with the semantics and the context of the sensors. More than isolated id and their ordered activation values\, sensors also carry meaning. Indeed\, their nature and type of activation can translate various activities. Their logs are correlated with each other\, creating a global context. We propose to use and compare two Natural Language Processing embedding methods to enhance LSTM-based structures in activity-sequences classification tasks: Word2Vec\, a static semantic embedding\, and ELMo\, a contextualized embedding. Results\, on real smart homes datasets\, indicate that this approach provides useful information\, such as a sensor organization map\, and makes less confusion between daily activity classes. It helps to better perform on datasets with competing activities of other residents or pets. Our tests show also that the embeddings can be pretrained on different datasets than the target one\, enabling transfer learning. We thus demonstrate that taking into account the context of the sensors and their semantics increases the classification performances and enables transfer learning.","Human activity recognition,Deep learning,Smart home,Ambient assisting living,Language model,Contextualized model,Long short-term memory,LSTM,Transfer learning,Ambient sensors,Word2Vec,ELMo,Semantic model","Damien Bouchabou,Sao Mai Nguyen,Christophe Lohr,Benoit Leduc,Ioannis Kanellos",2021,en
Densifying SLAM for UAV navigation by fusion of monocular depth prediction,"Simultaneous Localization and Mapping (SLAM) research has reached a level of maturity enabling systems to build autonomously an accurate sparse map of the environment while localizing themselves in that map. At the same time\, the use of deep learning has recently brought great improvements in Monocular Depth Prediction (MDP). Some applications such as autonomous drone navigation and obstacle avoidance require dense structure information and cannot only rely on sparse SLAM representation. We propose to densify a state-of-theart SLAM algorithm using deep learning-based dense MDP at keyframe rate. Towards this goal\, we describe a scale recovery from SLAM landmarks by minimizing a depth error metric combined with a multi-view depth refinement using a volumetric approach. We conclude with experiments that attest the added value of our approach in terms of depth estimation.","Usar,Monocular depth prediction,Deep-learning,Drones","Yassine Habib,Panagiotis Papadakis,Cédric Le Barz,Antoine Fagette,Tiago Gonçalves,Cédric Buche",2023,en
PRIM Project: Playing and Recording with Interactivity and Multisensoriality,"Multisensory Interaction (M.I.) is a promising research field acting on both perception and cognition. Among benefits, including the ""design for all"" approach, it is expected to increase humans’ cognitive performance (such as learning and cognitive stimulation) as well as user's experience. To our knowledge, there is no convincing tool allowing researchers to create easily multisensory scenarios, exercises or experimental interaction situations. This paper introduces the PRIM project which aims at designing a new and original tool for designing multisensory interactive interaction situations.","multisensory interaction, graphical language, user experience, accessibility","Céline Jost,Justin Debloos,Dominique Archambault,Brigitte Le Pevedic,Rémy Sohier,Jack Sagot,Charles Tijus,Isis Truck,Gérard Uzan",2021,en
Towards Automata-Based Abstraction of Goals in Hierarchical Reinforcement Learning,"Hierarchical Reinforcement Learning (HRL) offers potential benefits for solving long horizon tasks\, generally unhandled by standard Reinforcement Learning (RL) techniques\, by decomposing the problem and combining simple policies to achieve the goal. They are however still held back by the curse of dimensionality and the ambiguity of selected subtasks. We explore relevant approaches in HRL while highlighting the key challenges of goal representation\, high-level planning and propose a research outline tackling them.",,"Mehdi Zadem,Sergio Mover,Sao Mai Nguyen,Sylvie Putot",2022,en
"Reinforcement Learning based\, Staircase Negotiation Learning in Simulation and Transfer to Reality for Articulated Tracked Robots","Autonomous control of reconfigurable robots is crucial for their deployment in diverse environments. The development of such skills is however hampered by the diversity in hardware and task constraints. We advocate the use of artificial intelligence-based approaches to improve scalability to different conditions and portability to platforms of comparable traversability skills. In particular\, we succeed in tackling the problem of staircase traversal via a reinforcement learning-based control framework applicable to different articulated tracked robots\, powerful enough to generalize to varying conditions learnt in simulation and to transfer to reality in a zero-shot setting. Our extensive experiments demonstrate the robustness of the framework in learning tasks with increased risk and difficulty induced by platform diversification and increased control dimensionality.",,"Andrei Mitriakov,Panagiotis Papadakis,Jérôme Kerdreux,Serge Garlatti",2021,en
Fully Convolutional Network Bootstrapped by Word Encoding and Embedding for Activity Recognition in Smart Homes,"Activity recognition in smart homes is essential when we wish to propose automatic services for the inhabitants. However\, it poses challenges in terms of variability of the environment\, sensorimotor system\, but also user habits. Therefore\, endto-end systems fail at automatically extracting key features\, without extensive pre-processing. We propose to tackle feature extraction for activity recognition in smart homes by merging methods from the Natural Language Processing (NLP) and the Time Series Classification (TSC) domains. We evaluate the performance of our method on two datasets issued from the Center for Advanced Studies in Adaptive Systems (CASAS). Moreover\, we analyze the contributions of the use of NLP encoding Bag-Of-Word with Embedding as well as the ability of the FCN algorithm to automatically extract features and classify. The method we propose shows good performance in offline activity classification. Our analysis also shows that FCN is a suitable algorithm for smart home activity recognition and hightlights the advantages of automatic feature extraction.","Human Activity Recognition,Smart Homes,Embedding,Word Encoding,Fully Convolutional Network,Automatic Features","Damien Bouchabou,Sao Mai Nguyen,Christophe Lohr,Ioannis Kanellos,Benoit Leduc",2021,en
