title_s,abstract_s,keyword_s,authFullName_s,publicationDateY_i,language_s
Commonsense Reasoning for Identifying and Understanding the Implicit Need of Help and Synthesizing Assistive Actions,"Human-Robot Interaction (HRI) is an emerging subfield of service robotics. While most existing approaches rely on explicit signals (i.e. voice\, gesture) to engage\, current literature is lacking solutions to address implicit user needs. In this paper\, we present an architecture to (a) detect user implicit need of help and (b) generate a set of assistive actions without prior learning. Task (a) will be performed using state-of-the-art solutions for Scene Graph Generation coupled to the use of commonsense knowledge; whereas\, task (b) will be performed using additional commonsense knowledge as well as a sentiment analysis on graph structure. Finally\, we propose an evaluation of our solution using established benchmarks (e.g. ActionGenome dataset) along with human experiments. The main motivation of our approach is the embedding of the perception-decision-action loop in a single architecture.","Commonsense Reasoning,Knowledge Graph,Vision-to-Language,Cognitive Robotics,Sentiment Analysis,Scene Graph Generation","Maëlic Neau,Paulo Santos,Anne-Gwenn Bosser,Nathan Beu,Cédric Buche",2022,en
Indifferent or Enthusiastic? Virtual Audiences Animation and Perception in Virtual Reality,"In this paper\, we present a virtual audience simulation system for Virtual Reality (VR). The system implements an audience perception model controlling the nonverbal behaviors of virtual spectators\, such as facial expressions or postures. Groups of virtual spectators are animated by a set of nonverbal behavior rules representing a particular audience attitude (e.g.\, indifferent or enthusiastic). Each rule specifies a nonverbal behavior category: posture \, head movement \, facial expression and gaze direction as well as three parameters: type \, frequency and proportion . In a first user-study\, we asked participants to pretend to be a speaker in VR and then create sets of nonverbal behaviour parameters to simulate different attitudes. Participants manipulated the nonverbal behaviours of single virtual spectator to match a specific levels of engagement and opinion toward them. In a second user-study\, we used these parameters to design different types of virtual audiences with our nonverbal behavior rules and evaluated their perceptions. Our results demonstrate our system’s ability to create virtual audiences with three types of different perceived attitudes: indifferent \, critical \, enthusiastic . The analysis of the results also lead to a set of recommendations and guidelines regarding attitudes and expressions for future design of audiences for VR therapy and training applications.",,"Yann Glémarec,Jean-Luc Lugrin,Anne-Gwenn Bosser,Aryana Collins Jackson,Cédric Buche,Marc Erich Latoschik",2021,en
Improving Neural Architecture Search by Mixing a FireFly algorithm with a Training Free Evaluation,"Neural Architecture Search (NAS) algorithms are used to automate the design of deep neural networks. Finding the best architecture for a given dataset can be time consuming since these algorithms have to explore a large number of networks\, and score them according to their performances to choose the most appropriate one. In this work\, we propose a novel metric that uses the Intra-Cluster Distance (ICD) score to evaluate the ability of an untrained model to distinguish between data in order to approximate its quality. We also use an improved version of the FireFly algorithm\, more robust to the local optimums problem than the baseline FireFly algorithm\, as a search technique to find the best neural network model adapted to a specific dataset. Experimental results on the different NAS Benchmarks show that our metric is valid for either scoring CNNs and RNNs\, and that our proposed FireFly algorithm can improve the result obtained by the state-of-art training-free methods",,"Nassim Mokhtari,Alexis Nédélec,Marlene Gilles,Pierre de Loor",2022,en
When Non-Experts Search for Scientific Texts CLEF 2023 action report SimpleText,"Users tend to stay away from credible sources such as scientific literature due to their intricate language or their lack of prior knowledge. Rather, they depend on shallow sources from the web or social media that can be published for economic or political motives rather than for their enlightening value. Text simplification might remove some of these barriers. This paper presents the report on the CLEF 2023 SimpleText track aiming to encourage the research on automatic simplification of scientific texts by providing reusable data and benchmarks.","Scientific texts,Simplification,Information retrieval","Liana Ermakova,Stéphane Huet,Eric SanJuan,Olivier Augereau,Hosein Azarbonyad,Jaap Kamps",2023,fr
Pushing Out the Classroom Walls: A Scalability Benchmark for a Virtual Audience Behaviour Model in Virtual Reality,"In this paper\, we describe the implementation and performance of a Virtual Audience behaviour model for Virtual Reality (VR). The model is a VR adaptation of an existing desktop model based on crowd-sourced data. The system allows a user in VR to easily build and experience a wide variety of atmospheres with small or large groups of virtual agents. The paper describes the model's implementation and possible benefits for different applications\, e.g. training\, therapeutic or culture. Our first scalability benchmark results demonstrated the ability to simultaneously handle one hundred virtual agents without significantly affecting the recommended frame rate for VR applications. Lastly\, we propose a set of improvements our training system can benefit from. This research is conducted in the context of a classroom simulation software for teachers' training. CCS CONCEPTS • Human-centered computing → Virtual reality; • Software and its engineering → Virtual worlds training simulations.","Virtual Reality,Behaviour Model,Education,Virtual Agent","Yann Glémarec,Jean-Luc Lugrin,Anne-Gwenn Bosser,Paul Cagniat,Cédric Buche,Marc Erich Latoschik",2020,en
Conference Talk Training With a Virtual Audience System,"This paper presents the first prototype of a virtual audience system (VAS) specifically designed as a training tool for conference talks. This system has been tailored for university seminars dedicated to the preparation and delivery of scientific talks. We describe the required features which have been identified during the development process. We also summarize the preliminary feedback received from lecturers and students during the first deployment of the system in seminars for bachelor and doctoral students. Finally\, we discuss future work and research directions. We believe our system architecture and features are providing interesting insights on the development and integration of VR-based educational tools into university curriculum.","Virtual Reality,Virtual Agent,Education,Training Simulation","Yann Glémarec,Jean-Luc Lugrin,Anne-Gwenn Bosser,Cédric Buche,Marc Erich Latoschik",2021,en
Poetic or Humorous Text Generation: Jam Event at PFIA2022,"In this paper\, we describe the organization and the results of a Jam event on computational creativity at a major French national conference in AI PFIA2022. During this Jam event\, participants were challenged by the task of humor or poetry generation using a number of resources and corpus.","Computational creativity,Computational Humour,Humour generation,Wordplay,Artificial Intelligence,Scientific mediation,Large pre-trained models,Few-shot learning","Anne-Gwenn Bosser,Liana Ermakova,Florence Dupin de Saint-Cyr,Pierre de Loor,Victor Charpenay,Nicolas Pépin-Hermann,Benoît Alcaraz,Jean-Victor Autran,Alexandre Devillers,Juliette Grosset,Aymeric Hénard,Florian Marchal",2022,en
ICIDS2020 Panel: Building the Discipline of Interactive Digital Narratives,,,"Mark Bernstein,Mirjam Palosaari Eladhari,Hartmut Koenitz,Sandy Louchart,Frank Nack,Chris Martens,Giulia Carla Rossi,Anne-Gwenn Bosser,David Millard",2020,en
Limits of XAI application-grounded evaluation: an e-sport prediction example,"EXplainable AI (XAI) was created to address the issue of Machine Learning's lack of transparency. Its methods are expanding\, as are the ways of evaluating them\, including human performance-based evaluations of explanations. These evaluations allow us to quantify the contribution of XAI algorithms to human decision-making. This work performs accuracy and response time measurements to evaluate SHAP explanations on an e-sports prediction task. The results of this pilot experiment contradict our intuitions about the beneficial potential of these explanations and allow us to discuss the difficulties of this evaluation methodology.",XAI,"Corentin Boidot,Olivier Augereau,Pierre de Loor,Riwal Lefort",2022,en
Speech Perception and Implementation in a Virtual Medical Assistant,"In emergency medical procedures\, positive and trusting interactions between followers and leaders are imperative. That interaction is even more important when a virtual agent assumes the leader role and a human assumes the follower role. In order to manage the human-computer interaction\, situational leadership is employed to match the human follower to an appropriate leadership style embodied by the agent. Situational leadership was used to create 33 utterances indicative of the four different leadership styles. A participant evaluation was then carried out in order to examine (1) whether perceptions of leader trust and motivation vary dependent on both readiness level and utterance syntax and (2) whether follower ability and willingness are affected by the leader’s speech. We found that general perceptions of leadership behavior influenced follower performance and that the leader’s speech influences followers’ ability. Finally\, we demonstrate how the results of this study are implemented in a virtual agent system.","Situational leadership,Medicine,Speech,Virtual agent,Embodied conversational agent","Aryana Collins Jackson,Yann Glémarec,Elisabetta Bevacqua,Pierre de Loor,Ronan Querrec",2022,en
Effect of Context and Distance Switching on Visual Performances in Augmented Reality,"Augmented reality may lead the user to repeatedly look at different environments (real/virtual) and at different distances to process information. We studied how context and distance switching could (together or separately) affect users' performances. 29 participants (16 video game players) performed two tasks that required to switch between two screens (visual search and target detection task). These screens could be virtual (using HoloLens2) or real and placed at 1.5 or 2 meters. Distance switching had an impact only on visual search performances. Participants' levels of experience with video games modified the effect of context switching.","augmented reality,context switching,distance switching,visual attention,attentional shift","Mathilde Drouot,Nathalie Le Bigot,Jean-Louis de Bougrenet de La Tocnaye,Vincent Nourrit",2021,en
"Audience simulation and perception in virtual reality.","Many training or exposure therapy applications simulate audiences in virtual reality (VR) to provide safe and ecological environments. However\, audience simulation in VR presents many challenges related to creating attitudes from the agents' non-verbal behaviour. Furthermore\, in VR\, the animations and the realism of the characters\, also called agents\, can also create performance problems. The behaviour models used in these systems are not directly evaluated in VR and rely on online studies or the application domain experts' knowledge. Thus\, the difference in technology and the user perception subjectivity could influence evaluations' results. Therefore\, we propose an audience behaviour model evaluated in VR that generates the non-verbal behaviours of its members from a given attitude to improve the audiences' quality and facilitate their use in educational and therapeutic scenarios. We present a series of performance and user perception evaluations in VR aiming at validating the system's ability to simulate different types of attitudes (bored\, interested or critical) while preserving an optimal VR experience and providing a high-level control application facilitating seamless attitude change in real-time\, notably for the creation of training scenarios. Finally\, we validate the deployment feasibility of this model in training and exposure therapy applications used by professionals.","Virtual reality,Virtual Agent,Virtual audience,Non-verbal behaviour,Réalité virtuelle,Agent Virtuel,Audience virtuelle,Comportement non-verbal",Yann Glémarec,2023,en
Simulations of a Computational Model for a Virtual Medical Assistant,"We propose a virtual medical assistant to guide both novice and expert caregivers through a procedure without the direct help of medical professionals. Our medical assistant uses situational leadership to handle all interaction with a caregiver\, which works by identifying the readiness level of the caregiver in order to match them with an appropriate style of communication. The agent system (1) obtains caregiver behavior during the procedure\, (2) calculates a readiness level of the caregiver using that behavior\, and (3) generates appropriate agent behavior to progress the procedure and maintain a positive interaction with the caregiver.","Intelligent Agents,Embodied Conversational Agents,Human-computer Interaction,Situational Leadership,Medicine,Simulation","Aryana Collins Jackson,Marlène Gilles,Eimar Wall,Elisabetta Bevacqua,Pierre de Loor,Ronan Querrec",2022,en
Augmented reality on industrial assembly line: Impact on effectiveness and mental workload,"Studies examining the potential of augmented reality (AR) to improve assembly tasks are often unrepresentative of real assembly line conditions and assess mental workload only through subjective measurements and leads to conflicting results. We proposed a study directly carried out in industrial settings\, to compare the impact of ARbased instructions to computerized instructions\, on assembly effectiveness (completion time and errors) and mental workload using objective (eye tracking)\, subjective (NASA-TLX) and behavioral measurements (dual task paradigm). According to our results\, AR did not improve effectiveness (increased assembly times and no decrease in assembly errors). Two out of three measurements indicated that AR led to more mental workload for simple assembly workstation\, but equated computer instructions for complex workstation. Our data also suggest that\, AR users were less able to detect external events (danger\, alert)\, which may play an important role in the occurrence of work accidents.",,"Mathilde Drouot,Nathalie Le Bigot,Emmanuel Bricard,Jean-Louis De Bougrenet,Vincent Nourrit",2022,en
An Open Platform for Research about Cognitive Load in Virtual Reality,"The cognitive load can be used to assess if someone is struggling while performing a task. It can be used in many different situations such as in driving\, piloting\, studying\, playing\, working\, etc. This information can help to design better systems and even to create interactive systems that can be aware of the user's cognitive load and adapt itself to the user. We propose an open source platform that can be used for doing research about cognitive load in virtual reality (VR). Our platform can be used for stimulating cognitive load through several VR scenes and for analyzing cognitive load through objective and subjective measurements.","Cognitive load,Open Acces,Virtual reality,Psychology Cognitive","Olivier Augereau,Gabriel Brocheton,Pedro Paulo Do Prado Neto",2022,en
Humorous Wordplay Generation in French,"Recent work have tackled the problem of generating puns in English\, based on the corpus of English puns from SemEval 2017 Task 7. In this paper\, we report on experiments on generating French puns based on the data released for the CLEF 2022 JOKER and inspired by methods for generating English puns with large pretrained models. 50% of generated wellerisms were funny.","Computational Humour,Humour generation,Wordplay,Wellerism,Word embedding,Large pre-trained models,Few-shot learning,Lexique 3,Computational creativity","Loïc Glémarec,Anne-Gwenn Bosser,Julien Boccou,Liana Ermakova",2022,en
"RoboCup@Home Education 2020 Best Performance: RoboBreizh\, a modular approach","Every year\, the Robocup@Home competition challenges teams and robots' abilities. In 2020\, the RoboCup@Home Education challenge was organized online\, altering the usual competition rules. In this paper\, we present the latest developments that lead the RoboBreizh team to win the contest. These developments include several modules linked to each other allowing the Pepper robot to understand\, act and adapt itself to a local environment. Up-to-date available technologies have been used for navigation and dialogue. First contribution includes combining object detection and pose estimation techniques to detect user's intention. Second contribution involves using Learning by Demonstrations to easily learn new movements that improve the Pepper robot's skills. This proposal won the best performance award of the 2020 RoboCup@Home Education challenge.",,"Antoine Dizet,Cédric Le Bono,Amélie Legeleux,Maëlic Neau,Cédric Buche",2021,en
Impact of Public Lighting Intensity on the Feeling of Safety in Virtual Reality,"Over the past decades the urban night landscapes have been associated with over-lighting\, which has become the norm. Arguably\, lighting systems play a major role in the city life (feeling of safety\, development of a night time economy and various night practices). But the urge for reducing energy consumption and protecting biodiversity must be considered while designing public lighting\, without compromising the feeling of safety. In this paper\, researchers from Urban Planning\, Psychology and Computer Science were gathered by the transdisciplinary research program ""Noz Breizh"". They are proposing an exploratory approach to use Virtual Reality to test different lighting intensities for studying its impact on the feeling of safety of pedestrians. As a first result we observed a logarithmic relation between the feeling of safety and the light intensity.","Urban Planning,Virtual Reality,Public Lighting,Well-being,Psychology,Safety","Olivier Augereau,Simon Bruno,Ignacio Pérez Allub,Edna Hernández González,Nathalie Le Bigot,Ronan Querrec",2023,en
The JOKER Corpus: English-French Parallel Data for Multilingual Wordplay Recognition,"Despite recent advances in information retrieval and natural language processing, rhetorical devices that exploit ambiguity or subvert linguistic rules remain a challenge for such systems. However, corpus-based analysis of wordplay has been a perennial topic of scholarship in the humanities, including literary criticism, language education, and translation studies. The immense data-gathering effort required for these studies points to the need for specialized text retrieval and classification technology, and consequently for appropriate test collections. In this paper, we introduce and analyze a new dataset for research and applications in the retrieval and processing of wordplay. Developed for the JOKER track at CLEF 2023, our annotated corpus extends and improves upon past English wordplay detection datasets in several ways. First, we introduce hundreds of additional positive examples of wordplay; second, we provide French translations for the examples; and third, we provide negative examples of non-wordplay with characteristics closely matching those of the positive examples. This last feature helps ensure that AI models learn to effectively distinguish wordplay from non-wordplay, and not simply texts differing in length, style, or vocabulary. Our test collection represents then a step towards wordplay-aware multilingual information retrieval.","annotated datasets for machine learning, wordplay retrieval & analysis, parallel corpora, wordplay detection, wordplay location, text classification","Liana Ermakova,Anne-Gwenn Bosser,Adam Jatowt,Tristan Miller",2023,en
"Towards the identification of procedural learning phases in a virtual environment","Virtual environments used to acquire skills generate large amounts of behavioral data and thus provide new opportunities to understand learners' activity. From such data\, a clustering method was used in the present study to identify phases in the procedural learning process. The recognition of these phases from a behavioral point of view would allow to follow in real time and in an automatic way the progress of the individuals and thus to personalize the pedagogical scenarios in a virtual environment. Sixty-three participants repeatedly performed a Soma cube assembly procedure in a virtual environment. Analyses show an improvement in performance and a decrease in cognitive cost as the task is repeated. The results of a multidimensional approach of dividing the activity into different phases are presented and discussed.","Procedural learning,Mental workload,Behavioral data,Virtual environment,Learning phases","Anais Raison,Olivier Augereau,Nathalie Le Bigot,Frédéric Devillers,Sébastien Levieux,Franck Ganier",2023,fr
Trust in Automation: Analysis and Model of Operator Trust in Decision Aid AI Over Time,"Understanding how human trust in AI evolves over time is essential to identify the limits of each party and provide solutions for optimal collaboration. With this goal in mind\, we examine the factors that directly or indirectly influence trust\, whether they come from humans\, AI\, or the environment. We then propose a summary of methods for measuring trust\, whether subjective or objective\, to show which ones are best suited for longitudinal studies. We then focus on the main driving force behind the evolution of trust: feedback. We justify how learning feedback can be transposed to trust and what types of feedback can be applied to impact the evolution of trust over time. After understanding the factors that influence and how to measure trust\, we propose an application example on a maritime surveillance tool with an AI-based decision aid.","Trust in Automation,Maritime Patrol,Longitudinal Experiment,Feedback,Human Factors,Cognitive Engineering","Vincent Fer,Daniel Lafond,Gilles Coppin,Mathias Bollaert,Olivier Grisvard,Pierre de Loor",2023,en
Assessing the Believability of Computer Players in Video Games: A New Protocol and Computer Tool,"In this paper\, we address the challenge of believability in multiplayer video games. Our contribution is a system for assessing the believability of computer players. The state of the art examines existing methods and identifies seven distinguishing features that differ considerably from one assessment to the next. Our investigation reveals that assessment procedures typically alter gameplay\, posing a considerable danger of bias. This is a major flaw since computer players are evaluated in a specific context rather than in the context of the game as it should be played\, potentially skewing the findings of the evaluation. As a result\, we begin on a trial-and-error process\, with each new proposal building on the achievements of the previous one while removing the flaws. New proposals are tested with new assessments\, a total of three experiments are then presented. We created a computer program that partially automates the execution of the assessment procedure\, making these trials easier to implement. At the end\, thanks to our proposal\, gamers can assess the believability of computer players indirectly by employing reporting forms that alert users to the presence of bots. We assume that the more a bot is reported\, the less credible it becomes. We ran a final experiment to test our proposal\, which yielded extremely encouraging results.",,"Cindy Even,Anne-Gwenn Bosser,Cédric Buche",2021,en
The visual impact of augmented reality during an assembly task,"Many studies have shown the benefits of augmented reality (AR) to improve manufacturingand control processes in industry. However, the presentation of AR content through optical seethrough head-mounted displays may induce unnatural viewing conditions, which consequences on theuser’s visual system have not been investigated yet. This study aimed at assessing whether using ARinstructions to guide a manual task, i.e., conditions where the user is forced to repeatedly look at andaccommodate in different planes to extract information from both real and virtual environments, couldpotentially impact the visual system of operators. A before/after design study was carried out, asking26 participants to perform Lego assemblies for 30 minutes with either paper or AR instructions. Theeffects of using AR compared to paper instructions were evaluated both on binocular vision, withclassical optometric measurements, and on visual fatigue, with the Virtual Reality SymptomsQuestionnaire. No clinically significant differences in optometric measurements (far/near visual acuity,stereoacuity, phoria, convergence, fusional amplitude, accommodation amplitude, accommodativeconvergence) have been found between AR and paper instructions, and only negligible fatiguesymptoms have been seen specifically for AR. Results from both objective and subjectivemeasurements suggest that there is no impact of AR on the oculomotor system and that, in thisspecific case of use, AR can be safely used for production operators.","augmented reality, optometry, visual fatigue, manual assembly, vergence-accommodation conflict, focal distance switching.","Mathilde Drouot,Nathalie Le Bigot,Johanne Bolloc'H,Emmanuel Bricard,Jean-Louis de Bougrenet,Vincent Nourrit",2021,en
Eye Got It: A System for Automatic Calculation of the Eye-Voice Span,"Over the past decade, eye movement has been widely lookedinto for describing and analyzing several cognitive processes and especially for human-document interaction, such as estimating reading ability and document understanding. Most of the existing applications havebeen done for silent reading but we propose to explore reading aloud interaction through a powerful measurement named the “eye-voice span”which measures the distance between the eyes and the voice. In thispaper we present an open-source platform named “Eye got it” and theunderlying algorithms that can be used for processing eye-tracking andvoice data in order to compute automatically the eye-voice span.","Eye Tracking · Eye-voice span · Human-document interaction · Voice analysis","Mohamed El Baha,Olivier Augereau,Sofiya Kobylyanskaya,Ioana Vasilescu,Laurence Devillers",2022,en
Science for Fun: The CLEF 2023 JOKER Track on Automatic Wordplay Analysis,"Understanding and translating humorous wordplay often requires recognition of implicit cultural references\, knowledge of word formation processes\, and discernment of double meanings – issues which pose challenges for humans and computers alike. This paper introduces the CLEF 2023 JOKER track\, which takes an interdisciplinary approach to the creation of reusable test collections\, evaluation metrics\, and methods for the automatic processing of wordplay. We describe the track’s interconnected shared tasks for the detection\, location\, interpretation\, and translation of puns. We also describe associated data sets and evaluation methodologies\, and invite contributions making further use of our data.","Wordplay,Puns,Humour,Wordplay interpretation,Wordplay detection,Wordplay generation,Machine translation","Liana Ermakova,Tristan Miller,Anne-Gwenn Bosser,Victor Manuel Palma Preciado,Grigori Sidorov,Adam Jatowt",2023,en
Designing Speech with Computational Linguistics for a Virtual Medical Assistant Using Situational Leadership,"In emergency medical procedures\, positive and trusting interaction between followers and leaders are imperative. That interaction is even more important when a virtual agent assumes the leader role and a human assumes the follower role. In order to manage the human-computer interaction\, situational leadership is employed to match the human to an appropriate leadership style embodied by the agent. This paper explores how different leadership styles can be conveyed by a virtual agent through an analysis of utterances made by doctors and coordinators during emergency simulations. We create a corpus which comprises utterances from simulation videos of medical emergencies. Each utterance is annotated with a leadership style. After analysis involving k-means clustering\, we compile easily-reproducible rules that dictate how speech should appear in each leadership style for use in a virtual agent system.",,"Aryana Collins Jackson,Elisabetta Bevacqua,Pierre de Loor,Ronan Querrec",2021,en
Benefits of using multiple post-hoc explanations for Machine Learning,"EXplainable AI (XAI) offers a wide range of algorithmic solutions to the problem of AI's opacity\, but ensuring of their usefulness remains a challenge. In this study\, we propose an multi-explanation XAI system using surrogate rules\, LIME and nearest neighbor on a random forest. Through an experiment in an e-sports prediction task\, we demonstrate the feasibility and measure the usefulness of working with multiple forms of explanation. Considering users' preferences\, we offer new perspectives for XAI design and evaluation\, highlighting the concept of data difficulty and of the idea of prior agreement between users and AI.",XAI,"Corentin Boidot,Olivier Augereau,Pierre de Loor,Riwal Lefort",2023,en
CLEF 2023 SimpleText Track ⋆ What Happens if General Users Search Scientific Texts?,"The general public tends to avoid reliable sources such as scientific literature due to their complex language and lacking background knowledge. Instead\, they rely on shallow and derived sources on the web and in social media-often published for commercial or political incentives\, rather than the informational value. Can text simplification help to remove some of these access barriers? This paper presents the CLEF 2023 SimpleText track tackling technical and evaluation challenges of scientific information access for a general audience. We provide appropriate reusable data and benchmarks for scientific text simplification\, and promote novel research to reduce barriers in understanding complex texts. Our overall use-case is to create a simplified summary of multiple scientific documents based on a popular science query which provides a user with an accessible overview on this specific topic. The track has the following three concrete tasks. Task 1 (What is in\, or out?): selecting passages to include in a simplified summary. Task 2 (What is unclear?): difficult concept identification and explanation. Task 3 (Rewrite this!): text simplification-rewriting scientific text. The three tasks together form a pipeline of a scientific text simplification system.","Summarization,Scientific text simplification,Multi-document summarization,Terminology extraction,Keyword extraction,Contextualization,Background knowledge,Scientific information distortion,Information retrieval","Liana Ermakova,Eric Sanjuan,Stéphane Huet,Olivier Augereau,Hosein Azarbonyad,Jaap Kamps",2023,en
Semi-automatic narrative comprehension for debriefing simulation sessions,"In this paper, we describe the results of the STRATEGICproject about the semi-automatic storification of activitytraces of simulation sessions used for training. New representation tools will make it possible to generate thumbnails corresponding to the decisive moments identified bythe operator in a narrative graph and thus to propose asynthesis of the overall progress of the scenario illustrated by instantaneous “photographs” of the tactical situation. This will facilitate debriefing, and promote cooperative learning.","Sensemaking, Storifications","Ariane Bitoun,Anne-Gwenn Bosser,Martín Diéguez,Francois Legras",2022,fr
Contrastive Visual and Language Learning for Visual Relationship Detection,"Visual Relationship Detection (VRD) aims to understand real-world objects' interactions by grounding visual concepts to compositional visual relation triples\, written in the form of (subject\, predicate\, object). Previous work explored the use of contrastive learning to implicitly predict predicates (representing relations) from the relevant image regions. However\, these models often directly leverage in-distribution spatial and language co-occurrences biases during training\, preventing the models from generalizing to out-of-distribution compositions. In this work\, we examined whether contrastive vision and language models\, pre-trained on largescale external image and text datasets\, can assist the detection of compositional visual relations. To this end\, we propose a contrastive fine-tuning approach for the VRD task. The results obtained from this investigation show that larger models yield better performance when compared with their smaller counterparts\, while models pre-trained on larger datasets do not necessarily present the best performance.","Visual Relationship Detection,Deep Learning,Computer Vision","Thanh Tran,Maëlic Neau,Paulo E. Santos,David Powers",2022,en
Improving Collaborative Learning in Virtual Reality With Facial Expressions,"This article presents an approach to improve collaborative learning in terms of performance & satisfaction through the generation of non-verbal behavior of users displayed on their avatar in virtual reality. Various works have focused on the behavioral realism of avatars\, which can considerably improve interactions. The purpose of this paper is to investigate the impact of displaying the facial expressions of a user in real time on the performance of the task\, the satisfaction and the behavioral changes of the users interacting in a virtual environment. To evaluate this approach\, we carried out a study where the users collaborated to build a TV stand in dyad including a novice (the participant) and an expert assistant (the experimenter).","Virtual Reality,Collaboration,Non verbal communication,Facial expressions","Hugo Le Tarnec,Olivier Augereau,Elisabetta Bevacqua,Pierre de Loor",2022,en
Towards a behavioral approach to distinguishing procedural learning phases: the case of an assembly procedure in a virtual environment,"Virtual environments used to acquire procedures and transfer them to real-life situations often lack adaptability to the learning rhythm of individual learners. The aim of the present study was to analyze the progress of procedural learning and to examine the relevance of a behavioral indicator to automatically identify procedural learning phases in real time. Identifying the progression of each learner would enable adapting teaching scenarios. Sixty-three individuals participated in the experiment to learn a Soma cube assembly procedure in a virtual environment\, based on graphical instructions. Analysis of the activity traces and mental workload showed a progression in performance and a reduction in cognitive cost as the task was practiced. A proposal for dividing learners' activity into phases is analyzed\, and prospects for improvement are provided.","Procedural learning,Mental workload,Behavioral data,Virtual learning environment,Learning phases,Apprentissage de procédure,Charge de travail mental,Données comportementales,Environnement virtuel pour l'apprentissage humain,Phases d'apprentissage","Anais Raison,Nathalie Le Bigot,Olivier Augereau,Franck Ganier",2023,fr
A review of Virtual Assistants' characteristics: recommendations for designing an optimal human-machine cooperation,"Abstract Designed to improve human-machine interactions\, virtual agents\, and particularly virtual assistants (VAs)\, are spreading in our daily lives. Presenting a very wide variety of characteristics\, studies generally report their own agent with its own characteristics and objective. So we can wonder if some of these characteristics are a consensus for VAs in general. Within this work\, we aim to identify the agents' characteristics that should be considered when designing a virtual assistant promoting the best communication and cooperation between man and machine. We review the aspects of representation of the agent (embodied or not) and its ability to interact with the human being whether by speech or gestures\, but also by displaying personality traits. This overview makes some focuses on virtual assistance of any kind embarked on vehicles.",Virtual assistant,"Marlène Gilles,Elisabetta Bevacqua",2021,en
Controlling the Stage: A High-Level Control System for Virtual Audiences in Virtual Reality,"This article presents a novel method for controlling a virtual audience system (VAS) in Virtual Reality (VR) application\, called STAGE\, which has been originally designed for supervised public speaking training in university seminars dedicated to the preparation and delivery of scientific talks. We are interested in creating pedagogical narratives : narratives encompass affective phenomenon and rather than organizing events changing the course of a training scenario\, pedagogical plans using our system focus on organizing the affects it arouses for the trainees. Efficiently controlling a virtual audience towards a specific training objective while evaluating the speaker’s performance presents a challenge for a seminar instructor: the high level of cognitive and physical demands required to be able to control the virtual audience\, whilst evaluating speaker’s performance\, adjusting and allowing it to quickly react to the user’s behaviors and interactions. It is indeed a critical limitation of a number of existing systems that they rely on a Wizard of Oz approach\, where the tutor drives the audience in reaction to the user’s performance. We address this problem by integrating with a VAS a high-level control component for tutors\, which allows using predefined audience behavior rules\, defining custom ones\, as well as intervening during run-time for finer control of the unfolding of the pedagogical plan. At its core\, this component offers a tool to program\, select\, modify and monitor interactive training narratives using a high-level representation. The STAGE offers the following features: i) a high-level API to program pedagogical narratives focusing on a specific public speaking situation and training objectives\, ii) an interactive visualization interface iii) computation and visualization of user metrics\, iv) a semi-autonomous virtual audience composed of virtual spectators with automatic reactions to the speaker and surrounding spectators while following the pedagogical plan V) and the possibility for the instructor to embody a virtual spectator to ask questions or guide the speaker from within the Virtual Environment. We present here the design\, and implementation of the tutoring system and its integration in STAGE\, and discuss its reception by end-users.","Virtual Agents,Virtual reality,Behavior perception,Public speaking,Education","Yann Glémarec,Jean-Luc Lugrin,Anne-Gwenn Bosser,Cédric Buche,Marc Erich Latoschik",2022,en
"RoboBreizh\, RoboCup@Home SSPL Champion 2022","This paper presents the approach employed by the team RoboBreizh to win the championship in the 2022 RoboCup@Home Social Standard Platform League (SSPL). RoboBreizh decided to limit itself to an entirely embedded system with no connection to the internet and external devices. This article describes the design of embedded solutions including manager, navigation, dialog and perception. We present results from the competition showing up the value of our proposal.",,"Cédric Buche,Maëlic Neau,Thomas Ung,Louis Li,Tianjiao Jiang,Mukesh Barange,Maël Bouabdelli",2023,en
Unsupervised Learning of State Representation using Balanced View Spatial Deep InfoMax: Evaluation on Atari Games,"In this paper\, we present an unsupervised state representation learning of spatio-temporally evolving sequences of autonomous agents' observations. Our method uses contrastive learning through mutual information (MI) maximization between a sample and the views derived through selection of pixels from the sample and other randomly selected negative samples. Our method employs balancing MI by finding the optimal ratios of positive-to-negative pixels in these derived (constructed) views. We performed several experiments and determined the optimal ratios of positive-to-negative signals to balance the MI between a given sample and the constructed views. The newly introduced method is named as Balanced View Spatial Deep InfoMax (BVS-DIM). We evaluated our method on Atari games and performed comparisons with the state-of-the-art unsupervised state representation learning baseline method. We show that our solution enables to successfully learn state representations from sparsely sampled or randomly shuffled observations. Our BVS-DIM method also marginally enhances the representation powers of encoders to capture high-level latent factors of the agents' observations when compared with the baseline method.","Unsupervised Learning Autonomous Agents State Representation Learning Contrastive Learning Atari Games,Unsupervised Learning,Autonomous Agents,State Representation Learning,Contrastive Learning,Atari Games","Menore Tekeba Mengistu,Getachew Alemu,Pierre Chevaillier,Pierre de Loor",2022,en
Human Activity Recognition: A Spatio-temporal Image Encoding of 3D Skeleton Data for Online Action Detection,"Human activity recognition (HAR) based on skeleton data that can be extracted from videos (Kinect for example) \, or provided by a depth camera is a time series classification problem\, where handling both spatial and temporal dependencies is a crucial task\, in order to achieve a good recognition. In the online human activity recognition\, identifying the beginning and end of an action is an important element\, that might be difficult in a continuous data flow. In this work\, we present a 3D skeleton data encoding method to generate an image that preserves the spatial and temporal dependencies existing between the skeletal joints.To allow online action detection we combine this encoding system with a sliding window on the continous data stream. By this way\, no start or stop timestamp is needed and the recognition can be done at any moment. A deep learning CNN algorithm is used to achieve actions online detection.","Online Action Recognition,Human Activity Recognition,Deep Learning,Deep learning,3D Skeleton Data,Spatio-temporal Image Encoding,Sliding Window","Nassim Mokhtari,Alexis Nédélec,Pierre de Loor",2022,en
A Computational Interaction Model for a Virtual Medical Assistant Using Situational Leadership,"In a medical emergency in which an amateur caregiver is separated from medical experts by space and/or time, a virtual assistant could be useful in order to guide the caregiver through the required procedure successfully. A successful procedure is one that preserves and improves the health of the patient and maintains a positive interaction between the caregiver and the assistant. Regardless of whether the caregiver is experienced in the tasks in the procedure, the assistant must be able to guide them through each step. To manage the interaction between the assistant and caregiver, we employ situational leadership. We propose an agent system for (1) obtaining caregiver behavior during the procedure, (2) assigning a follower style to the caregiver, (3) determining the appropriate leadership style for the assistant, and (4) generating appropriate agent behavior to progress the procedure and maintain a positive interaction with the caregive","human-computer interaction; embodied conversational agents; intelligent agents; situational leadership; medicine","Aryana Collins Jackson,Elisabetta Bevacqua,Pierre de Loor,Ronan Querrec",2021,en
